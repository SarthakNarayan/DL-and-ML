{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SarthakNarayan/DL-and-ML/blob/master/googlecolab/Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2y5PCw7GKlOY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "def sigmoid(x):\n",
        "    activation = 1/(1 + torch.exp(-x))\n",
        "    return activation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbYjgqdNOBGs",
        "colab_type": "code",
        "outputId": "e9b18ff2-eaea-4109-c942-29b0779c214c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "torch.manual_seed(23)\n",
        "weights = torch.randn((5,1))\n",
        "print(weights)\n",
        "print(weights.shape)\n",
        "weights = torch.reshape(weights , (1,5))\n",
        "print(\"sum of all the weights {}\".format(torch.sum(weights)))\n",
        "print(\"sum of all the weights {}\".format(weights.sum()))\n",
        "features = torch.randn((5,1))\n",
        "bias = torch.randn((1,1))\n",
        "# More advisable to use mm since it is strict about the shapes whereas matmul supports broadcasting\n",
        "y_hat = torch.add(torch.mm(weights,features),bias)\n",
        "print(\"y_hat before activation\",y_hat)\n",
        "y_hat = sigmoid(y_hat)\n",
        "print(\"y_hat after activation\",y_hat)\n",
        "print(\"so we see sigmoid converts any value to between 1 and 0\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.8733],\n",
            "        [ 0.4376],\n",
            "        [-0.4866],\n",
            "        [-0.7840],\n",
            "        [-0.2983]])\n",
            "torch.Size([5, 1])\n",
            "sum of all the weights -2.004563570022583\n",
            "sum of all the weights -2.004563570022583\n",
            "y_hat before activation tensor([[1.2492]])\n",
            "y_hat after activation tensor([[0.7772]])\n",
            "so we see sigmoid converts any value to between 1 and 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcx-L8UdPk96",
        "colab_type": "code",
        "outputId": "10e87566-80af-4163-d8ff-b5575140ce32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "# normal * does element wise multiplication\n",
        "print(torch.tensor([1,2,3])*torch.tensor([1,2,3]))\n",
        "# torch.dot performs element wise multiplication and sums them\n",
        "print(torch.dot(torch.tensor([1,2,3]),torch.tensor([1,2,3])))\n",
        "a = torch.tensor([[1,2,3] , [1,2,3]])\n",
        "print(\"Sum along the columns {}\".format(torch.sum(a , dim = 0).numpy()))\n",
        "print(\"Sum along the rows {}\".format(torch.sum(a , dim = 1).numpy()))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1, 4, 9])\n",
            "tensor(14)\n",
            "Sum along the columns [2 4 6]\n",
            "Sum along the rows [6 6]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Si7s-0trRBT",
        "colab_type": "code",
        "outputId": "be4bcb7e-615e-4e21-a283-da6f213af139",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "a = torch.tensor([[1,2,3],[1,2,3]])\n",
        "print(a)\n",
        "print(a[0][0].item())\n",
        "# .item() only works for a scalar value and not any array\n",
        "# so a[0].item() will also not work"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1, 2, 3],\n",
            "        [1, 2, 3]])\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xdy6ywpjYnvT",
        "colab_type": "code",
        "outputId": "bc4b01b3-3fd8-4fc9-fb94-e407ca664dbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        }
      },
      "source": [
        "# multilayer perceptron\n",
        "torch.manual_seed(23)\n",
        "# w*x + b\n",
        "def multilayer_perceptron(no_of_features,no_of_hidden_units,no_output_nodes):\n",
        "    x = torch.randn((no_of_features , 1))\n",
        "    weights = torch.randn((no_of_hidden_units , no_of_features))\n",
        "    bias = torch.randn((no_of_hidden_units , 1))\n",
        "    h12 = torch.add(torch.mm(weights,x),bias)\n",
        "    print(h12)\n",
        "    h12 = sigmoid(h12)\n",
        "    print(h12)\n",
        "    weights = torch.randn((no_output_nodes , h12.shape[0]))\n",
        "    bias = torch.randn((no_output_nodes , 1))\n",
        "    h = torch.add(torch.mm(weights,h12),bias)\n",
        "    print(h)\n",
        "    y_hat = sigmoid(h)\n",
        "    print(y_hat)\n",
        "\n",
        "multilayer_perceptron(2,3,1)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.2699],\n",
            "        [-1.5522],\n",
            "        [ 2.2264]])\n",
            "tensor([[0.5671],\n",
            "        [0.1748],\n",
            "        [0.9026]])\n",
            "tensor([[-1.2120]])\n",
            "tensor([[0.2293]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ynTd0fnYxfV",
        "colab_type": "code",
        "outputId": "2e30eb5c-50cc-44ae-db27-0483eb92ae17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "# bridging numpy array with pytorch\n",
        "import numpy as np\n",
        "a = np.random.randn(1,2)\n",
        "print(a)\n",
        "b = torch.from_numpy(a)\n",
        "print(b)\n",
        "print(\"Back to numpy\")\n",
        "print(b.numpy())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.30194012 -1.34358464]]\n",
            "tensor([[ 0.3019, -1.3436]], dtype=torch.float64)\n",
            "Back to numpy\n",
            "[[ 0.30194012 -1.34358464]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Os0-94Hibfc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "851e959d-cd7f-420d-e4bd-6660bbc0d74b"
      },
      "source": [
        "# Using mnist data on my perceptron network\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor()])\n",
        "\n",
        "# to get the test set you set train = False\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "print(len(testset))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GYgW3DKjGO-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "645e14e1-eab4-4a53-e095-8273ef63ecce"
      },
      "source": [
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64,\n",
        "                                          shuffle=True)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64,\n",
        "                                         shuffle=True)\n",
        "print(\"Total number of batches {}\".format(len(testloader)))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of batches 157\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDmem8otjdP8",
        "colab_type": "code",
        "collapsed": true,
        "outputId": "9d70567b-b8d6-42d4-d5cb-e55faec64995",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2281
        }
      },
      "source": [
        "images , labels = next(iter(testloader))\n",
        "print(images.shape)\n",
        "images = images.reshape((64,-1))\n",
        "print(images.shape)\n",
        "torch.manual_seed(23)\n",
        "\n",
        "# x*w + b\n",
        "def multilayer_for_mnist(features,no_of_hidden_units,no_of_outputs):\n",
        "    x = features\n",
        "    w1 = torch.randn((features.shape[1] , no_of_hidden_units))\n",
        "    b1 = torch.randn((features.shape[0] , no_of_hidden_units))\n",
        "    h12 = torch.add(torch.matmul(x,w1) , b1)\n",
        "    h12 = sigmoid(h12)\n",
        "    w2 = torch.randn((h12.shape[1] , no_of_outputs))\n",
        "    b2 = torch.randn((h12.shape[0] , no_of_outputs))\n",
        "    h = torch.add(torch.matmul(h12,w2) , b2)\n",
        "    y_hat = sigmoid(h)\n",
        "    print(y_hat)\n",
        "    print(y_hat.shape)\n",
        "    return y_hat\n",
        "\n",
        "prediction = multilayer_for_mnist(images , 256 , 10)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64, 784])\n",
            "tensor([[1.3193e-05, 1.2243e-06, 1.8061e-08, 9.9994e-01, 9.9997e-01, 2.6585e-04,\n",
            "         1.0177e-02, 1.2834e-01, 9.9295e-01, 1.6512e-01],\n",
            "        [1.5857e-07, 1.2658e-04, 4.4665e-05, 9.9988e-01, 9.9998e-01, 5.1002e-05,\n",
            "         1.0000e+00, 1.2840e-09, 9.9731e-01, 6.9557e-07],\n",
            "        [6.2602e-05, 1.0784e-05, 1.3269e-09, 9.9971e-01, 9.9987e-01, 9.8132e-01,\n",
            "         8.1723e-03, 4.1878e-04, 9.8537e-01, 8.7561e-01],\n",
            "        [5.3138e-04, 1.1886e-01, 4.4868e-02, 9.9583e-01, 1.5463e-07, 2.6593e-04,\n",
            "         7.6947e-01, 2.3076e-05, 1.0000e+00, 5.7209e-06],\n",
            "        [2.5221e-08, 2.8505e-05, 1.6951e-01, 9.1777e-01, 1.0000e+00, 3.4459e-04,\n",
            "         9.8505e-01, 9.6499e-01, 9.9554e-01, 6.2495e-09],\n",
            "        [7.9909e-07, 3.1230e-02, 3.6103e-12, 5.9542e-01, 1.0000e+00, 2.1398e-01,\n",
            "         3.1596e-06, 1.4038e-07, 1.0000e+00, 1.9913e-02],\n",
            "        [7.2242e-04, 6.4985e-04, 6.4096e-06, 8.0812e-01, 1.8243e-04, 3.6842e-03,\n",
            "         9.8795e-01, 1.9260e-05, 1.0000e+00, 1.8827e-05],\n",
            "        [1.4122e-04, 6.0977e-02, 8.8194e-02, 9.9941e-01, 5.0136e-06, 2.5511e-04,\n",
            "         9.9998e-01, 3.2566e-04, 1.0000e+00, 3.1283e-07],\n",
            "        [1.4915e-08, 2.1359e-01, 1.7661e-02, 9.9456e-01, 9.1090e-01, 1.1077e-07,\n",
            "         9.0707e-01, 3.0962e-06, 1.0000e+00, 1.1612e-06],\n",
            "        [2.5271e-03, 9.9823e-01, 8.4015e-01, 8.9509e-01, 2.5499e-04, 1.1806e-02,\n",
            "         1.7477e-03, 2.4256e-04, 1.0000e+00, 1.6464e-07],\n",
            "        [1.1323e-08, 9.9998e-01, 1.2226e-03, 3.4733e-01, 9.9997e-01, 1.1385e-06,\n",
            "         1.3688e-01, 1.1888e-03, 1.0000e+00, 1.2963e-03],\n",
            "        [1.7737e-07, 1.2167e-02, 5.9115e-04, 1.0000e+00, 4.8632e-02, 2.0492e-09,\n",
            "         9.2493e-01, 6.1450e-04, 1.0000e+00, 8.0816e-09],\n",
            "        [3.0338e-09, 3.0107e-04, 1.9002e-05, 9.8479e-01, 9.9942e-01, 6.2303e-03,\n",
            "         9.5094e-01, 5.8449e-05, 9.9999e-01, 9.2175e-08],\n",
            "        [1.7192e-04, 3.0061e-08, 3.8079e-09, 9.9999e-01, 9.7621e-01, 6.5720e-01,\n",
            "         5.8807e-03, 1.5479e-03, 8.2289e-01, 5.0635e-01],\n",
            "        [3.1037e-01, 9.8156e-01, 2.5943e-08, 3.6834e-01, 9.8057e-01, 8.2913e-05,\n",
            "         9.8636e-01, 7.4188e-01, 9.9861e-01, 2.2108e-06],\n",
            "        [2.9508e-11, 2.3206e-03, 2.9062e-05, 1.0000e+00, 1.2409e-02, 8.8399e-09,\n",
            "         9.9999e-01, 3.3861e-03, 1.0000e+00, 6.5780e-01],\n",
            "        [3.3287e-09, 1.9367e-06, 2.2583e-02, 8.6485e-01, 9.9995e-01, 6.3109e-06,\n",
            "         9.9999e-01, 1.4992e-05, 9.9991e-01, 6.7270e-02],\n",
            "        [2.6601e-08, 3.1051e-03, 5.4753e-01, 9.9594e-01, 2.7385e-04, 3.0007e-04,\n",
            "         3.1275e-02, 1.1569e-02, 9.9998e-01, 2.0947e-10],\n",
            "        [1.6034e-02, 3.7304e-04, 2.7044e-06, 9.9654e-01, 1.0000e+00, 1.1746e-09,\n",
            "         1.5773e-02, 7.5829e-01, 1.0000e+00, 3.1328e-01],\n",
            "        [3.2100e-04, 5.5610e-02, 8.8677e-01, 1.7608e-01, 1.0000e+00, 6.1395e-01,\n",
            "         2.8451e-01, 1.4168e-02, 9.9993e-01, 1.2580e-07],\n",
            "        [5.5379e-09, 7.7813e-04, 3.6906e-01, 9.9985e-01, 4.3392e-01, 1.5931e-08,\n",
            "         9.5195e-01, 7.0825e-01, 1.0000e+00, 7.2508e-13],\n",
            "        [8.8606e-04, 4.4102e-02, 9.3530e-02, 4.4226e-01, 9.9816e-01, 3.3085e-04,\n",
            "         9.5563e-01, 3.0110e-06, 9.8908e-01, 1.1481e-01],\n",
            "        [1.7327e-09, 1.5688e-05, 5.6010e-08, 1.6639e-04, 1.0000e+00, 3.1187e-01,\n",
            "         6.4816e-02, 1.2759e-11, 1.0000e+00, 3.3488e-01],\n",
            "        [4.8549e-04, 2.4200e-01, 1.9032e-01, 9.9841e-01, 7.7951e-03, 1.6487e-05,\n",
            "         9.9961e-01, 9.3254e-03, 9.9541e-01, 1.5567e-05],\n",
            "        [8.6201e-08, 9.8443e-01, 7.6453e-02, 4.5468e-02, 7.9485e-01, 6.6665e-03,\n",
            "         9.1373e-02, 1.7990e-06, 1.0000e+00, 2.6674e-08],\n",
            "        [4.4860e-04, 7.7575e-06, 2.4241e-09, 1.0000e+00, 9.9999e-01, 4.4325e-03,\n",
            "         1.0945e-01, 9.5647e-01, 9.9999e-01, 6.6070e-03],\n",
            "        [8.7153e-05, 4.3974e-04, 8.8261e-01, 1.0000e+00, 8.2794e-01, 2.9193e-11,\n",
            "         9.9965e-01, 1.3657e-03, 1.0000e+00, 4.0891e-04],\n",
            "        [2.0264e-06, 4.9746e-09, 4.2741e-08, 9.4656e-02, 9.9999e-01, 7.4042e-02,\n",
            "         9.9997e-01, 2.6183e-10, 9.9979e-01, 4.5075e-02],\n",
            "        [4.0612e-08, 9.3928e-05, 1.2373e-03, 1.0000e+00, 8.1403e-01, 8.2687e-08,\n",
            "         9.9918e-01, 6.5098e-06, 1.0000e+00, 1.2454e-07],\n",
            "        [5.7517e-07, 9.9850e-01, 1.2760e-01, 9.8384e-01, 1.4434e-02, 2.4440e-07,\n",
            "         9.9992e-01, 6.7268e-06, 9.9999e-01, 1.9574e-08],\n",
            "        [6.7093e-07, 1.8688e-02, 1.0206e-06, 1.0000e+00, 6.3577e-01, 1.7841e-06,\n",
            "         9.8156e-01, 1.1919e-02, 1.0000e+00, 1.4145e-06],\n",
            "        [5.4229e-07, 8.2494e-04, 4.0393e-05, 9.9993e-01, 9.0895e-01, 7.5451e-10,\n",
            "         1.0000e+00, 3.3045e-06, 9.9995e-01, 3.1040e-03],\n",
            "        [9.7878e-10, 3.5113e-02, 3.7271e-01, 1.0000e+00, 3.4452e-06, 1.1602e-04,\n",
            "         9.4229e-01, 4.5900e-01, 9.9998e-01, 1.6020e-08],\n",
            "        [1.3742e-04, 8.6086e-01, 2.7227e-02, 9.9972e-01, 2.2085e-01, 3.7944e-06,\n",
            "         7.7225e-01, 1.4965e-01, 9.9976e-01, 2.3384e-07],\n",
            "        [3.4234e-10, 6.7673e-01, 3.2438e-02, 9.9992e-01, 1.8882e-02, 6.0536e-09,\n",
            "         4.2028e-03, 1.1825e-02, 9.9849e-01, 5.0264e-01],\n",
            "        [3.8688e-08, 6.1267e-01, 8.2112e-06, 9.9993e-01, 9.9988e-01, 1.5338e-02,\n",
            "         1.5683e-01, 6.1453e-04, 9.9999e-01, 1.2194e-03],\n",
            "        [5.0506e-07, 6.0942e-09, 2.2014e-05, 7.6080e-01, 9.9089e-01, 1.2065e-08,\n",
            "         9.8613e-01, 3.6130e-01, 8.2520e-01, 4.0652e-04],\n",
            "        [8.0046e-09, 2.8242e-04, 6.9446e-04, 9.9890e-01, 9.9560e-01, 6.3867e-07,\n",
            "         9.9999e-01, 1.8414e-01, 9.9979e-01, 7.0471e-01],\n",
            "        [2.0819e-06, 5.3462e-06, 1.1956e-04, 9.9998e-01, 8.9897e-02, 2.2158e-03,\n",
            "         7.5658e-01, 3.4140e-09, 9.6994e-02, 3.2029e-04],\n",
            "        [8.1343e-09, 2.0271e-02, 6.9548e-02, 1.0000e+00, 3.6518e-03, 1.5828e-07,\n",
            "         8.8520e-01, 9.4394e-05, 1.0000e+00, 3.3639e-04],\n",
            "        [8.2508e-03, 9.9986e-01, 5.7809e-01, 9.8072e-01, 2.2187e-03, 1.7255e-05,\n",
            "         9.9407e-01, 3.8329e-04, 1.0000e+00, 1.6331e-07],\n",
            "        [3.1308e-06, 6.9527e-01, 6.0745e-05, 9.2805e-01, 4.2820e-04, 6.3561e-04,\n",
            "         6.3586e-02, 1.0015e-05, 9.9555e-01, 8.5068e-07],\n",
            "        [8.1513e-10, 2.5770e-04, 9.4460e-01, 9.9847e-01, 9.9956e-01, 1.9922e-04,\n",
            "         9.9999e-01, 1.5775e-05, 9.9943e-01, 3.1366e-08],\n",
            "        [8.6810e-11, 4.8008e-02, 3.6244e-03, 1.2280e-02, 8.1219e-01, 1.0604e-06,\n",
            "         9.8563e-01, 8.1393e-01, 9.9989e-01, 1.5650e-06],\n",
            "        [3.1411e-07, 1.8430e-04, 1.4878e-07, 7.9183e-01, 1.0000e+00, 2.2345e-01,\n",
            "         1.6013e-02, 3.0472e-05, 1.0000e+00, 9.6753e-01],\n",
            "        [1.8021e-08, 2.8382e-01, 6.1383e-03, 9.9930e-01, 9.9581e-01, 7.7724e-05,\n",
            "         9.9998e-01, 2.1844e-05, 9.9998e-01, 1.0055e-04],\n",
            "        [2.4946e-04, 2.9154e-08, 1.8806e-09, 1.0000e+00, 1.0000e+00, 2.8652e-03,\n",
            "         3.9453e-04, 1.4854e-01, 9.9998e-01, 5.5497e-02],\n",
            "        [6.6439e-05, 7.3039e-06, 6.0286e-07, 8.5619e-01, 9.9992e-01, 6.9612e-05,\n",
            "         2.3846e-01, 1.8071e-03, 1.0000e+00, 1.2063e-02],\n",
            "        [1.3762e-04, 3.6901e-05, 9.0082e-01, 9.7544e-01, 6.3313e-01, 7.3042e-10,\n",
            "         1.0000e+00, 2.8231e-08, 1.0000e+00, 3.0733e-08],\n",
            "        [5.9714e-07, 1.0167e-03, 2.9970e-08, 5.7916e-01, 1.0000e+00, 9.9239e-01,\n",
            "         9.6376e-01, 2.4917e-08, 1.0000e+00, 2.3891e-02],\n",
            "        [5.7926e-05, 1.2895e-01, 3.5709e-02, 9.9666e-01, 4.2769e-01, 4.9165e-09,\n",
            "         9.9956e-01, 7.2252e-07, 9.9998e-01, 1.1205e-07],\n",
            "        [9.1855e-06, 6.8885e-02, 1.5530e-04, 6.0815e-01, 9.9987e-01, 9.7759e-10,\n",
            "         9.9998e-01, 6.6855e-03, 9.9900e-01, 1.7841e-07],\n",
            "        [1.2058e-06, 1.1577e-02, 2.0611e-01, 9.8663e-01, 8.3609e-09, 3.8764e-01,\n",
            "         1.0630e-01, 2.1307e-03, 9.9999e-01, 4.8110e-05],\n",
            "        [2.8896e-02, 9.0636e-03, 4.3667e-07, 9.9998e-01, 9.9846e-01, 7.8035e-03,\n",
            "         1.2938e-01, 2.7221e-01, 9.9996e-01, 2.1057e-05],\n",
            "        [1.0923e-02, 3.6376e-06, 2.4272e-03, 9.9999e-01, 1.0622e-01, 1.7232e-06,\n",
            "         9.9962e-01, 1.6050e-02, 9.7993e-01, 2.8232e-05],\n",
            "        [2.4771e-05, 5.5628e-01, 1.9399e-07, 1.0000e+00, 9.9998e-01, 1.3452e-05,\n",
            "         2.4654e-01, 1.1011e-01, 9.9980e-01, 2.0132e-03],\n",
            "        [1.9654e-10, 1.3510e-04, 1.4100e-05, 2.2578e-01, 9.1288e-01, 4.8788e-03,\n",
            "         9.8588e-01, 5.4494e-07, 9.9998e-01, 1.6516e-02],\n",
            "        [3.9692e-07, 1.2597e-03, 8.2701e-09, 2.4768e-02, 1.0000e+00, 1.5750e-03,\n",
            "         9.0669e-03, 2.9669e-06, 1.0000e+00, 9.3471e-05],\n",
            "        [1.5319e-05, 9.9930e-01, 9.9426e-01, 9.6121e-01, 1.1131e-01, 3.7687e-06,\n",
            "         9.9318e-01, 1.0865e-02, 1.0000e+00, 2.6323e-05],\n",
            "        [1.1168e-03, 9.8860e-01, 9.9153e-01, 9.9855e-01, 3.4463e-01, 2.9525e-07,\n",
            "         9.3924e-01, 3.6628e-01, 1.0000e+00, 5.8594e-09],\n",
            "        [8.0704e-05, 1.6189e-04, 3.4599e-04, 8.0948e-01, 1.0000e+00, 2.0925e-10,\n",
            "         5.4385e-03, 1.0111e-02, 1.0000e+00, 9.5847e-01],\n",
            "        [2.6221e-08, 2.8279e-08, 2.3363e-01, 9.9980e-01, 9.6382e-01, 2.8375e-05,\n",
            "         9.9677e-01, 2.8761e-06, 9.7610e-01, 1.7007e-06],\n",
            "        [8.7502e-03, 2.2140e-04, 2.6713e-05, 6.6107e-01, 9.9772e-01, 9.8891e-03,\n",
            "         9.9952e-01, 7.1559e-08, 9.9946e-01, 1.0055e-01],\n",
            "        [9.3156e-05, 3.5788e-05, 1.1596e-07, 9.8399e-01, 1.0000e+00, 8.2654e-04,\n",
            "         4.8531e-01, 1.3914e-06, 9.9518e-01, 8.7558e-06]])\n",
            "torch.Size([64, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWBRiwkBnx0N",
        "colab_type": "code",
        "collapsed": true,
        "outputId": "aa545a24-ccc0-4fe4-db8c-59cf567a29ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2281
        }
      },
      "source": [
        "def softmax(x):\n",
        "    x = torch.exp(x)\n",
        "    values = []\n",
        "    print(x.shape)\n",
        "    for i in range(x.shape[0]):\n",
        "        x[i] = x[i]/torch.sum(x[i] , dim = 0)\n",
        "    print(x.shape)\n",
        "    return x\n",
        "\n",
        "pred = softmax(prediction)\n",
        "print(pred)\n",
        "print(pred[0].sum(dim = 0))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 10])\n",
            "torch.Size([64, 10])\n",
            "tensor([[0.0647, 0.0647, 0.0647, 0.1758, 0.1758, 0.0647, 0.0653, 0.0735, 0.1746,\n",
            "         0.0763],\n",
            "        [0.0593, 0.0593, 0.0593, 0.1612, 0.1612, 0.0593, 0.1612, 0.0593, 0.1607,\n",
            "         0.0593],\n",
            "        [0.0550, 0.0550, 0.0550, 0.1494, 0.1494, 0.1467, 0.0554, 0.0550, 0.1473,\n",
            "         0.1320],\n",
            "        [0.0678, 0.0763, 0.0709, 0.1834, 0.0678, 0.0678, 0.1463, 0.0678, 0.1842,\n",
            "         0.0678],\n",
            "        [0.0543, 0.0543, 0.0643, 0.1360, 0.1476, 0.0543, 0.1454, 0.1425, 0.1469,\n",
            "         0.0543],\n",
            "        [0.0688, 0.0710, 0.0688, 0.1247, 0.1869, 0.0852, 0.0688, 0.0688, 0.1869,\n",
            "         0.0702],\n",
            "        [0.0683, 0.0683, 0.0682, 0.1531, 0.0683, 0.0685, 0.1833, 0.0682, 0.1855,\n",
            "         0.0682],\n",
            "        [0.0653, 0.0694, 0.0713, 0.1775, 0.0653, 0.0653, 0.1776, 0.0653, 0.1776,\n",
            "         0.0653],\n",
            "        [0.0601, 0.0744, 0.0612, 0.1625, 0.1494, 0.0601, 0.1488, 0.0601, 0.1633,\n",
            "         0.0601],\n",
            "        [0.0618, 0.1674, 0.1429, 0.1510, 0.0617, 0.0624, 0.0618, 0.0617, 0.1677,\n",
            "         0.0617],\n",
            "        [0.0636, 0.1729, 0.0637, 0.0900, 0.1729, 0.0636, 0.0729, 0.0637, 0.1729,\n",
            "         0.0637],\n",
            "        [0.0666, 0.0674, 0.0666, 0.1810, 0.0699, 0.0666, 0.1679, 0.0666, 0.1810,\n",
            "         0.0666],\n",
            "        [0.0599, 0.0599, 0.0599, 0.1602, 0.1626, 0.0602, 0.1549, 0.0599, 0.1627,\n",
            "         0.0599],\n",
            "        [0.0616, 0.0616, 0.0616, 0.1673, 0.1634, 0.1188, 0.0619, 0.0616, 0.1402,\n",
            "         0.1021],\n",
            "        [0.0732, 0.1432, 0.0536, 0.0775, 0.1430, 0.0537, 0.1439, 0.1127, 0.1456,\n",
            "         0.0536],\n",
            "        [0.0621, 0.0622, 0.0621, 0.1688, 0.0629, 0.0621, 0.1688, 0.0623, 0.1688,\n",
            "         0.1199],\n",
            "        [0.0602, 0.0602, 0.0615, 0.1429, 0.1635, 0.0602, 0.1635, 0.0602, 0.1635,\n",
            "         0.0643],\n",
            "        [0.0704, 0.0706, 0.1217, 0.1906, 0.0704, 0.0704, 0.0727, 0.0712, 0.1914,\n",
            "         0.0704],\n",
            "        [0.0609, 0.0600, 0.0600, 0.1624, 0.1630, 0.0600, 0.0609, 0.1280, 0.1630,\n",
            "         0.0820],\n",
            "        [0.0614, 0.0648, 0.1489, 0.0731, 0.1667, 0.1133, 0.0815, 0.0622, 0.1667,\n",
            "         0.0613],\n",
            "        [0.0587, 0.0587, 0.0848, 0.1594, 0.0905, 0.0587, 0.1520, 0.1191, 0.1595,\n",
            "         0.0587],\n",
            "        [0.0632, 0.0660, 0.0694, 0.0983, 0.1715, 0.0632, 0.1643, 0.0632, 0.1699,\n",
            "         0.0709],\n",
            "        [0.0701, 0.0701, 0.0701, 0.0701, 0.1905, 0.0957, 0.0748, 0.0701, 0.1905,\n",
            "         0.0980],\n",
            "        [0.0640, 0.0815, 0.0774, 0.1735, 0.0644, 0.0639, 0.1738, 0.0645, 0.1730,\n",
            "         0.0639],\n",
            "        [0.0674, 0.1804, 0.0728, 0.0705, 0.1492, 0.0678, 0.0738, 0.0674, 0.1832,\n",
            "         0.0674],\n",
            "        [0.0593, 0.0592, 0.0592, 0.1610, 0.1610, 0.0595, 0.0661, 0.1541, 0.1610,\n",
            "         0.0596],\n",
            "        [0.0560, 0.0560, 0.1353, 0.1522, 0.1281, 0.0560, 0.1521, 0.0561, 0.1522,\n",
            "         0.0560],\n",
            "        [0.0650, 0.0650, 0.0650, 0.0715, 0.1768, 0.0700, 0.1768, 0.0650, 0.1767,\n",
            "         0.0680],\n",
            "        [0.0609, 0.0609, 0.0610, 0.1656, 0.1375, 0.0609, 0.1655, 0.0609, 0.1656,\n",
            "         0.0609],\n",
            "        [0.0589, 0.1599, 0.0669, 0.1576, 0.0598, 0.0589, 0.1601, 0.0589, 0.1601,\n",
            "         0.0589],\n",
            "        [0.0624, 0.0636, 0.0624, 0.1696, 0.1178, 0.0624, 0.1665, 0.0632, 0.1696,\n",
            "         0.0624],\n",
            "        [0.0601, 0.0601, 0.0601, 0.1633, 0.1491, 0.0601, 0.1634, 0.0601, 0.1633,\n",
            "         0.0603],\n",
            "        [0.0622, 0.0644, 0.0903, 0.1691, 0.0622, 0.0622, 0.1596, 0.0985, 0.1691,\n",
            "         0.0622],\n",
            "        [0.0610, 0.1442, 0.0627, 0.1657, 0.0760, 0.0610, 0.1320, 0.0708, 0.1657,\n",
            "         0.0610],\n",
            "        [0.0661, 0.1301, 0.0683, 0.1798, 0.0674, 0.0661, 0.0664, 0.0669, 0.1795,\n",
            "         0.1093],\n",
            "        [0.0618, 0.1140, 0.0618, 0.1679, 0.1679, 0.0627, 0.0723, 0.0618, 0.1679,\n",
            "         0.0619],\n",
            "        [0.0616, 0.0616, 0.0616, 0.1318, 0.1659, 0.0616, 0.1652, 0.0884, 0.1406,\n",
            "         0.0616],\n",
            "        [0.0553, 0.0553, 0.0553, 0.1501, 0.1497, 0.0553, 0.1503, 0.0665, 0.1503,\n",
            "         0.1119],\n",
            "        [0.0766, 0.0766, 0.0767, 0.2083, 0.0839, 0.0768, 0.1633, 0.0766, 0.0844,\n",
            "         0.0767],\n",
            "        [0.0669, 0.0682, 0.0717, 0.1817, 0.0671, 0.0669, 0.1620, 0.0669, 0.1817,\n",
            "         0.0669],\n",
            "        [0.0573, 0.1544, 0.1013, 0.1515, 0.0569, 0.0568, 0.1536, 0.0568, 0.1545,\n",
            "         0.0568],\n",
            "        [0.0699, 0.1401, 0.0699, 0.1768, 0.0699, 0.0699, 0.0745, 0.0699, 0.1892,\n",
            "         0.0699],\n",
            "        [0.0542, 0.0542, 0.1395, 0.1472, 0.1474, 0.0542, 0.1474, 0.0542, 0.1473,\n",
            "         0.0542],\n",
            "        [0.0626, 0.0657, 0.0628, 0.0634, 0.1410, 0.0626, 0.1678, 0.1413, 0.1702,\n",
            "         0.0626],\n",
            "        [0.0605, 0.0605, 0.0605, 0.1334, 0.1643, 0.0756, 0.0614, 0.0605, 0.1643,\n",
            "         0.1591],\n",
            "        [0.0582, 0.0772, 0.0585, 0.1580, 0.1574, 0.0582, 0.1581, 0.0582, 0.1581,\n",
            "         0.0582],\n",
            "        [0.0651, 0.0650, 0.0650, 0.1768, 0.1768, 0.0652, 0.0651, 0.0755, 0.1768,\n",
            "         0.0687],\n",
            "        [0.0663, 0.0663, 0.0663, 0.1562, 0.1803, 0.0663, 0.0842, 0.0665, 0.1803,\n",
            "         0.0671],\n",
            "        [0.0574, 0.0574, 0.1412, 0.1521, 0.1080, 0.0574, 0.1559, 0.0574, 0.1559,\n",
            "         0.0574],\n",
            "        [0.0569, 0.0570, 0.0569, 0.1016, 0.1548, 0.1536, 0.1492, 0.0569, 0.1548,\n",
            "         0.0583],\n",
            "        [0.0631, 0.0718, 0.0654, 0.1709, 0.0968, 0.0631, 0.1714, 0.0631, 0.1715,\n",
            "         0.0631],\n",
            "        [0.0622, 0.0667, 0.0622, 0.1143, 0.1692, 0.0622, 0.1692, 0.0627, 0.1690,\n",
            "         0.0622],\n",
            "        [0.0703, 0.0711, 0.0864, 0.1885, 0.0703, 0.1036, 0.0782, 0.0704, 0.1910,\n",
            "         0.0703],\n",
            "        [0.0658, 0.0645, 0.0639, 0.1737, 0.1734, 0.0644, 0.0727, 0.0839, 0.1737,\n",
            "         0.0639],\n",
            "        [0.0663, 0.0656, 0.0658, 0.1783, 0.0730, 0.0656, 0.1783, 0.0667, 0.1748,\n",
            "         0.0656],\n",
            "        [0.0614, 0.1070, 0.0614, 0.1668, 0.1668, 0.0614, 0.0785, 0.0685, 0.1668,\n",
            "         0.0615],\n",
            "        [0.0659, 0.0660, 0.0659, 0.0826, 0.1643, 0.0663, 0.1767, 0.0659, 0.1792,\n",
            "         0.0670],\n",
            "        [0.0742, 0.0743, 0.0742, 0.0761, 0.2017, 0.0743, 0.0749, 0.0742, 0.2017,\n",
            "         0.0742],\n",
            "        [0.0538, 0.1462, 0.1455, 0.1407, 0.0602, 0.0538, 0.1453, 0.0544, 0.1463,\n",
            "         0.0538],\n",
            "        [0.0521, 0.1398, 0.1402, 0.1412, 0.0734, 0.0520, 0.1330, 0.0750, 0.1414,\n",
            "         0.0520],\n",
            "        [0.0613, 0.0613, 0.0613, 0.1378, 0.1667, 0.0613, 0.0617, 0.0619, 0.1667,\n",
            "         0.1599],\n",
            "        [0.0589, 0.0589, 0.0745, 0.1602, 0.1545, 0.0589, 0.1597, 0.0589, 0.1564,\n",
            "         0.0589],\n",
            "        [0.0622, 0.0617, 0.0617, 0.1195, 0.1673, 0.0623, 0.1676, 0.0617, 0.1676,\n",
            "         0.0682],\n",
            "        [0.0636, 0.0636, 0.0636, 0.1701, 0.1729, 0.0636, 0.1033, 0.0636, 0.1720,\n",
            "         0.0636]])\n",
            "tensor(1.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uw93JEaO0Pg0",
        "colab_type": "text"
      },
      "source": [
        "In pytorch it is a convention to assign criterion = nn.loss() class. <br/>\n",
        "Eg: - criterion = nn.CrossEntropyLoss()<br/>\n",
        "So the expected input to these loss function is the logits or the scores and not the softmax probablities.\n",
        "Eg: given below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5E--ABQxkpB",
        "colab_type": "code",
        "outputId": "26641a76-5713-46fe-b353-e5623b9c3f6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# New way of creating a sequential model\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "model = nn.Sequential(nn.Linear(784 , 128),\n",
        "                   nn.ReLU(),\n",
        "                   nn.Linear(128 , 64),\n",
        "                   nn.ReLU(),\n",
        "                   nn.Linear(64,10))\n",
        "\n",
        "images , labels = next(iter(trainloader))\n",
        "images = images.reshape(images.shape[0] , -1)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "logits = model(images)\n",
        "# so we see we are passing logits i.e. original values rather than the softmax probabilities\n",
        "loss = criterion(logits , labels)\n",
        "print(loss)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2.3045, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVeDbnnL5xlm",
        "colab_type": "text"
      },
      "source": [
        "Pytorch has this really great class named autograd which keeps track of the tensor operations performed by us and when you tell it to do a backwards pass it will go backwards through each of these operations and calculate gradients wrt the input parameters.<br/>\n",
        "In general we need to tell pytorch that we want to use auto grad on a specific tensor.\n",
        "Eg: - "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRLZL0EW6q1h",
        "colab_type": "code",
        "outputId": "c225ca46-391e-43d7-9d40-0a65d0ec4d9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "a = torch.tensor([1,2,3] , requires_grad=True , dtype = torch.float64)\n",
        "print(a)\n",
        "# this will tell pytorch to track the operations of this tensor and it can compute its gradient whenever needed.\n",
        "# you can also do it using\n",
        "with torch.no_grad():\n",
        "    b = torch.tensor([1,2,3] , dtype = torch.float64)\n",
        "print(b.requires_grad)\n",
        "\n",
        "# you can also do it globally for all the variables using\n",
        "# torch.set_grad_enabled(True)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1., 2., 3.], dtype=torch.float64, requires_grad=True)\n",
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tupXhSjp9niF",
        "colab_type": "code",
        "outputId": "30b03ac5-86f8-433a-98f6-3017659f877f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# Using autograd to compute the gradients\n",
        "# we just do a variable.backward() if we want to compute its graident\n",
        "a = torch.tensor([1,2,3] , requires_grad=True , dtype = torch.float64)\n",
        "y = (a ** 2).sum(dim = 0)\n",
        "# we have to do sum because we can perform backward pass only on a scalar value and not any vector\n",
        "print(y)\n",
        "print(\"Gradient without performing the backward pass {}\".format(a.grad))\n",
        "y.backward()\n",
        "print(\"Gradient after performing the backward pass {}\".format(a.grad.numpy()))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(14., dtype=torch.float64, grad_fn=<SumBackward2>)\n",
            "Gradient without performing the backward pass None\n",
            "Gradient after performing the backward pass [2. 4. 6.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOnSY_-aD--o",
        "colab_type": "text"
      },
      "source": [
        "Once we have our gradients we need optimizers to update the weights by using the gradients.<br/>\n",
        "We need to clear the gradients because pytorch accumulates gradients and we do it using\n",
        "**optimizer.zero_grad() before every training process**.<br/>\n",
        "A step with the optimizer updates the weights."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XLhtz-g_8Ec",
        "colab_type": "code",
        "outputId": "e83ab197-ec30-4796-f38c-39334388393d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        }
      },
      "source": [
        "# incase of neural networks pytorch automatically computes the gradient of weights by using autograd to note their computations\n",
        "print(\"Gradients of the weights before backward pass {}\".format(model[0].weight.grad))\n",
        "loss.backward()\n",
        "print(\"Gradients of the weights after backward pass {}\".format(model[0].weight.grad))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gradients of the weights before backward pass None\n",
            "Gradients of the weights after backward pass tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xlm6K4CeJTb4",
        "colab_type": "code",
        "outputId": "c7a97133-32ed-4e5d-a171-01400cbe8856",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        }
      },
      "source": [
        "import torch.optim as optim\n",
        "optimizer = optim.SGD(model.parameters() , lr = 1e-3)\n",
        "optimizer.zero_grad()\n",
        "print(\"weights before stepping\" , model[0].weight)\n",
        "optimizer.step()\n",
        "print(\"Weights after stepping\" , model[0].weight)\n",
        "# not much of a difference since our graident was different"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "weights before stepping Parameter containing:\n",
            "tensor([[ 0.0122, -0.0171,  0.0267,  ...,  0.0208, -0.0134, -0.0082],\n",
            "        [ 0.0259, -0.0189, -0.0171,  ..., -0.0160, -0.0106,  0.0283],\n",
            "        [ 0.0339, -0.0078, -0.0324,  ...,  0.0244,  0.0031,  0.0294],\n",
            "        ...,\n",
            "        [-0.0109,  0.0095,  0.0027,  ...,  0.0306, -0.0105,  0.0120],\n",
            "        [-0.0180, -0.0165,  0.0315,  ..., -0.0054,  0.0217,  0.0048],\n",
            "        [ 0.0267,  0.0102,  0.0338,  ...,  0.0135,  0.0035, -0.0196]],\n",
            "       requires_grad=True)\n",
            "Weights after stepping Parameter containing:\n",
            "tensor([[ 0.0122, -0.0171,  0.0267,  ...,  0.0208, -0.0134, -0.0082],\n",
            "        [ 0.0259, -0.0189, -0.0171,  ..., -0.0160, -0.0106,  0.0283],\n",
            "        [ 0.0339, -0.0078, -0.0324,  ...,  0.0244,  0.0031,  0.0294],\n",
            "        ...,\n",
            "        [-0.0109,  0.0095,  0.0027,  ...,  0.0306, -0.0105,  0.0120],\n",
            "        [-0.0180, -0.0165,  0.0315,  ..., -0.0054,  0.0217,  0.0048],\n",
            "        [ 0.0267,  0.0102,  0.0338,  ...,  0.0135,  0.0035, -0.0196]],\n",
            "       requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbZCm45qZRhd",
        "colab_type": "text"
      },
      "source": [
        "Since for validation we dont need to train there is no need of having autograd track all the variables. So we do <br/>\n",
        "with torch.no_grad(): <br/>\n",
        "for images, labels in testloader <br/>\n",
        " We only need enumerate if we want to keep track of the number of epochs for verbosity.<br/>\n",
        "Put the validation loop inside the with segment. It saves us some computation.<br/>\n",
        "The general idea is after each forward pass of the epoch we want to calculate our validation accuracy. Eg: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5Da3LqLN0tH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Using dropouts in a model\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Network , self).__init__()\n",
        "        self.fc1 = nn.Linear(784 , 256)\n",
        "        self.fc2 = nn.Linear(256 , 128)\n",
        "        self.fc3 = nn.Linear(128 , 64)\n",
        "        self.fc4 = nn.Linear(64 , 10)\n",
        "        \n",
        "        self.dropout = nn.Dropout(p=0.2)\n",
        "    def forward(self , x):\n",
        "        x = x.reshape(x.shape[0] , -1)\n",
        "        x = self.dropout(F.relu(self.fc1(x)))\n",
        "        x = self.dropout(F.relu(self.fc2(x)))\n",
        "        x = self.dropout(F.relu(self.fc3(x)))\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "# Better of using GPU\n",
        "net = Network().cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkTzfJFae5QL",
        "colab_type": "text"
      },
      "source": [
        "Using dropouts<br/>\n",
        "Dont use dropout in the last layer.<br/>\n",
        "We want to do use dropout only for training and not for testing hence we have to use something known as model.eval().<br/>\n",
        "It turns of dropouts when we are doing validation,testing or even predictions.<br/>\n",
        "Then again to set our model back to training mode we use model.train(). This is particularly important when we are calculating validation accuracy since we will be training first then calculating the accuracy for that epoch and again doing the training for the next epoch so if we dont do model.train() our model wont consider dropouts while training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtblrKgxe7v6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "f38e054f-b302-42c3-d5ff-aecd8a5e9a83"
      },
      "source": [
        "# Calculating validation accuracy along with training\n",
        "num_epochs = 3\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters() , lr = 1e-3)\n",
        "for i in range(num_epochs):\n",
        "    running_loss = 0\n",
        "    counter = 0\n",
        "    for images , labels in trainloader:\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        optimizer.zero_grad()\n",
        "        logits = net(images)\n",
        "        loss = criterion(logits , labels)\n",
        "        running_loss += loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    # since you are calculating loss for the whole batch and not each image\n",
        "    print(\"Training Loss after {} epoch is {}\".format(i , (running_loss/len(trainloader))))\n",
        "    \n",
        "    net.eval()\n",
        "    correct = 0\n",
        "    accuracy = 0\n",
        "    for images_test , labels_test in testloader:\n",
        "        with torch.no_grad():\n",
        "            images_test = images_test.cuda()\n",
        "            labels_test = labels_test.cuda()\n",
        "            pred = net(images_test)\n",
        "            values , indices = torch.max(pred , 1)\n",
        "            for j in range(len(indices)):\n",
        "                if(indices[j] == labels_test[j]):\n",
        "                    correct = correct + 1\n",
        "    accuracy = (correct/len(testset))*100\n",
        "    # we can print validation loss if we want\n",
        "    print(\"Validation accuracy after {} epoch is {}\".format(i , accuracy))\n",
        "    net.train()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Loss after 0 epoch is 0.3807568848133087\n",
            "Validation accuracy after 0 epoch is 95.94\n",
            "Training Loss after 1 epoch is 0.1532614380121231\n",
            "Validation accuracy after 1 epoch is 97.28\n",
            "Training Loss after 2 epoch is 0.11407080292701721\n",
            "Validation accuracy after 2 epoch is 97.38\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWMVZ_kn5NCF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2d890e89-98ec-4f01-aefc-d29cc3c2cd27"
      },
      "source": [
        "# using torch.max()\n",
        "a = torch.tensor([[1,2,3],[1,2,3]])\n",
        "value , index = torch.max(a , 1)\n",
        "print(value,index)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([3, 3]) tensor([2, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCi0TqzgEkMA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "collapsed": true,
        "outputId": "197f56f3-d014-4eaf-e73b-fd9544f1ea5c"
      },
      "source": [
        "print(net)\n",
        "# print(net.state_dict())\n",
        "print(net.state_dict().keys())\n",
        "# to see the weights and gradients of any layer\n",
        "print(net.fc1.weight)\n",
        "print(net.fc1.weight.grad)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Network(\n",
            "  (fc1): Linear(in_features=784, out_features=256, bias=True)\n",
            "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
            "  (fc3): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
            "  (dropout): Dropout(p=0.2)\n",
            ")\n",
            "odict_keys(['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias', 'fc4.weight', 'fc4.bias'])\n",
            "Parameter containing:\n",
            "tensor([[ 0.0117,  0.0168, -0.0059,  ..., -0.0282,  0.0282, -0.0257],\n",
            "        [ 0.0303,  0.0050, -0.0117,  ...,  0.0045,  0.0092,  0.0134],\n",
            "        [ 0.0160,  0.0058,  0.0004,  ..., -0.0165, -0.0272,  0.0135],\n",
            "        ...,\n",
            "        [ 0.0278, -0.0309,  0.0178,  ...,  0.0137, -0.0182,  0.0210],\n",
            "        [ 0.0250, -0.0041, -0.0332,  ...,  0.0018,  0.0316, -0.0334],\n",
            "        [ 0.0076, -0.0048,  0.0079,  ...,  0.0194, -0.0271,  0.0053]],\n",
            "       requires_grad=True)\n",
            "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcxWBxRcF4uT",
        "colab_type": "text"
      },
      "source": [
        "For loading datasets we use torchvision<br/>\n",
        "trainset = dataset.ImageFolder('path' , transform = transforms)<br/>\n",
        "It expects that different classes should be in different folders<br/>\n",
        "Dont play too much with the transforms of test data set.<br/>\n",
        "Most common transforms for both training and testing are random crop , resize , totensor \n",
        "and rotation,horizontal flip for training.\n",
        "\n",
        "**Transfer Learning**<br/>\n",
        "Most of the models are pretrained on input images of 224*224 also we will need to match the normalization. The means are [0.485 , 0.456 , 0.406] and std is [0.229 , 0.224 , 0.225]<br/>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8T6QY31yF2ki",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 8692
        },
        "collapsed": true,
        "outputId": "2b4927a3-f101-4a9a-a6a3-a0d25dbe7de1"
      },
      "source": [
        "from torchvision import models,datasets,transforms\n",
        "transfer_model = models.densenet121(pretrained=True)\n",
        "print(transfer_model)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/checkpoints/densenet121-a639ec97.pth\n",
            "100%|██████████| 32342954/32342954 [00:00<00:00, 112757313.38it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "DenseNet(\n",
            "  (features): Sequential(\n",
            "    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu0): ReLU(inplace)\n",
            "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (denseblock1): _DenseBlock(\n",
            "      (denselayer1): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer2): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer3): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer4): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer5): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer6): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (transition1): _Transition(\n",
            "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "    )\n",
            "    (denseblock2): _DenseBlock(\n",
            "      (denselayer1): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer2): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer3): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer4): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer5): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer6): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer7): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer8): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer9): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer10): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer11): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer12): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (transition2): _Transition(\n",
            "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "    )\n",
            "    (denseblock3): _DenseBlock(\n",
            "      (denselayer1): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer2): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer3): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer4): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer5): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer6): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer7): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer8): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer9): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer10): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer11): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer12): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer13): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer14): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer15): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer16): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer17): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer18): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer19): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer20): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer21): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer22): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer23): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer24): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (transition3): _Transition(\n",
            "      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace)\n",
            "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "    )\n",
            "    (denseblock4): _DenseBlock(\n",
            "      (denselayer1): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer2): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer3): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer4): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer5): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer6): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer7): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer8): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer9): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer10): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer11): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer12): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer13): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer14): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer15): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (denselayer16): _DenseLayer(\n",
            "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu1): ReLU(inplace)\n",
            "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu2): ReLU(inplace)\n",
            "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "    )\n",
            "    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (classifier): Linear(in_features=1024, out_features=1000, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7nVkTFlPMeH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We need to retrain the classifier part and keep the feature part static\n",
        "for param in transfer_model.parameters():\n",
        "    param.requires_grad = False\n",
        "# This will make sure all the parameters are frozen and we dont compute their gradients hence making the execution faster\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}