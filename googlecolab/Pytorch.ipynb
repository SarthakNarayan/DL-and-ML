{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SarthakNarayan/DL-and-ML/blob/master/googlecolab/Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2y5PCw7GKlOY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "def sigmoid(x):\n",
        "    activation = 1/(1 + torch.exp(-x))\n",
        "    return activation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbYjgqdNOBGs",
        "colab_type": "code",
        "outputId": "dd66441d-1240-45ed-ad83-ec6583fc8b86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "torch.manual_seed(23)\n",
        "weights = torch.randn((5,1))\n",
        "print(weights)\n",
        "print(weights.shape)\n",
        "weights = torch.reshape(weights , (1,5))\n",
        "print(\"sum of all the weights {}\".format(torch.sum(weights)))\n",
        "print(\"sum of all the weights {}\".format(weights.sum()))\n",
        "features = torch.randn((5,1))\n",
        "bias = torch.randn((1,1))\n",
        "# More advisable to use mm since it is strict about the shapes whereas matmul supports broadcasting\n",
        "y_hat = torch.add(torch.mm(weights,features),bias)\n",
        "print(\"y_hat before activation\",y_hat)\n",
        "y_hat = sigmoid(y_hat)\n",
        "print(\"y_hat after activation\",y_hat)\n",
        "print(\"so we see sigmoid converts any value to between 1 and 0\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.8733],\n",
            "        [ 0.4376],\n",
            "        [-0.4866],\n",
            "        [-0.7840],\n",
            "        [-0.2983]])\n",
            "torch.Size([5, 1])\n",
            "sum of all the weights -2.004563570022583\n",
            "sum of all the weights -2.004563570022583\n",
            "y_hat before activation tensor([[1.2492]])\n",
            "y_hat after activation tensor([[0.7772]])\n",
            "so we see sigmoid converts any value to between 1 and 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcx-L8UdPk96",
        "colab_type": "code",
        "outputId": "41943601-a76e-4b9f-e5b9-a6fafb57764f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "# normal * does element wise multiplication\n",
        "print(torch.tensor([1,2,3])*torch.tensor([1,2,3]))\n",
        "# torch.dot performs element wise multiplication and sums them\n",
        "print(torch.dot(torch.tensor([1,2,3]),torch.tensor([1,2,3])))\n",
        "a = torch.tensor([[1,2,3] , [1,2,3]])\n",
        "print(\"Sum along the columns {}\".format(torch.sum(a , dim = 0).numpy()))\n",
        "print(\"Sum along the rows {}\".format(torch.sum(a , dim = 1).numpy()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1, 4, 9])\n",
            "tensor(14)\n",
            "Sum along the columns [2 4 6]\n",
            "Sum along the rows [6 6]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Si7s-0trRBT",
        "colab_type": "code",
        "outputId": "bee8dd63-94c2-4e5a-ce93-c91599669c05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "a = torch.tensor([[1,2,3],[1,2,3]])\n",
        "print(a)\n",
        "print(a[0][0].item())\n",
        "# .item() only works for a scalar value and not any array\n",
        "# so a[0].item() will also not work"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1, 2, 3],\n",
            "        [1, 2, 3]])\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xdy6ywpjYnvT",
        "colab_type": "code",
        "outputId": "5897fd23-26f0-4cf9-c1a6-d94c217bdcf8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        }
      },
      "source": [
        "# multilayer perceptron\n",
        "torch.manual_seed(23)\n",
        "# w*x + b\n",
        "def multilayer_perceptron(no_of_features,no_of_hidden_units,no_output_nodes):\n",
        "    x = torch.randn((no_of_features , 1))\n",
        "    weights = torch.randn((no_of_hidden_units , no_of_features))\n",
        "    bias = torch.randn((no_of_hidden_units , 1))\n",
        "    h12 = torch.add(torch.mm(weights,x),bias)\n",
        "    print(h12)\n",
        "    h12 = sigmoid(h12)\n",
        "    print(h12)\n",
        "    weights = torch.randn((no_output_nodes , h12.shape[0]))\n",
        "    bias = torch.randn((no_output_nodes , 1))\n",
        "    h = torch.add(torch.mm(weights,h12),bias)\n",
        "    print(h)\n",
        "    y_hat = sigmoid(h)\n",
        "    print(y_hat)\n",
        "\n",
        "multilayer_perceptron(2,3,1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.2699],\n",
            "        [-1.5522],\n",
            "        [ 2.2264]])\n",
            "tensor([[0.5671],\n",
            "        [0.1748],\n",
            "        [0.9026]])\n",
            "tensor([[-1.2120]])\n",
            "tensor([[0.2293]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ynTd0fnYxfV",
        "colab_type": "code",
        "outputId": "e5a02677-9c21-44cd-b0b6-ed1b0fcc3a98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "# bridging numpy array with pytorch\n",
        "import numpy as np\n",
        "a = np.random.randn(1,2)\n",
        "print(a)\n",
        "b = torch.from_numpy(a)\n",
        "print(b)\n",
        "print(\"Back to numpy\")\n",
        "print(b.numpy())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.22598667 -0.71195098]]\n",
            "tensor([[ 0.2260, -0.7120]], dtype=torch.float64)\n",
            "Back to numpy\n",
            "[[ 0.22598667 -0.71195098]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Os0-94Hibfc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Using mnist data on my perceptron network\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor()])\n",
        "\n",
        "# to get the test set you set train = False\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
        "                                       download=True, transform=transform)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GYgW3DKjGO-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64,\n",
        "                                          shuffle=True)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64,\n",
        "                                         shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDmem8otjdP8",
        "colab_type": "code",
        "collapsed": true,
        "outputId": "3538a380-dd1e-4201-dd78-aff3aa43cb29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2281
        }
      },
      "source": [
        "images , labels = next(iter(testloader))\n",
        "print(images.shape)\n",
        "images = images.reshape((64,-1))\n",
        "print(images.shape)\n",
        "torch.manual_seed(23)\n",
        "\n",
        "# x*w + b\n",
        "def multilayer_for_mnist(features,no_of_hidden_units,no_of_outputs):\n",
        "    x = features\n",
        "    w1 = torch.randn((features.shape[1] , no_of_hidden_units))\n",
        "    b1 = torch.randn((features.shape[0] , no_of_hidden_units))\n",
        "    h12 = torch.add(torch.matmul(x,w1) , b1)\n",
        "    h12 = sigmoid(h12)\n",
        "    w2 = torch.randn((h12.shape[1] , no_of_outputs))\n",
        "    b2 = torch.randn((h12.shape[0] , no_of_outputs))\n",
        "    h = torch.add(torch.matmul(h12,w2) , b2)\n",
        "    y_hat = sigmoid(h)\n",
        "    print(y_hat)\n",
        "    print(y_hat.shape)\n",
        "    return y_hat\n",
        "\n",
        "prediction = multilayer_for_mnist(images , 256 , 10)"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64, 784])\n",
            "tensor([[1.0140e-06, 1.6277e-03, 1.7026e-08, 9.8876e-01, 9.9998e-01, 1.0787e-03,\n",
            "         1.8629e-03, 4.0380e-02, 1.0000e+00, 3.9304e-03],\n",
            "        [2.5650e-08, 7.9059e-01, 3.6959e-02, 9.9790e-01, 9.7231e-01, 6.0422e-03,\n",
            "         3.6543e-02, 1.5973e-04, 9.9998e-01, 2.9609e-06],\n",
            "        [3.0122e-08, 2.8184e-02, 3.5271e-03, 8.3564e-01, 9.2835e-02, 9.7794e-06,\n",
            "         1.4428e-02, 1.1955e-03, 9.9934e-01, 1.4494e-06],\n",
            "        [8.5594e-05, 1.5545e-03, 1.6076e-02, 1.0348e-02, 9.6728e-01, 2.2726e-06,\n",
            "         1.2918e-04, 2.7442e-07, 1.0000e+00, 9.5435e-02],\n",
            "        [5.0165e-09, 1.0841e-03, 2.7352e-04, 9.9992e-01, 9.9986e-01, 9.4051e-04,\n",
            "         1.0000e+00, 1.7940e-08, 9.9997e-01, 9.3537e-03],\n",
            "        [5.3375e-06, 2.4105e-02, 2.1962e-04, 3.9990e-01, 9.9632e-01, 5.2315e-01,\n",
            "         1.0000e+00, 8.4743e-12, 1.0000e+00, 2.4772e-03],\n",
            "        [1.5910e-05, 3.1016e-08, 3.9229e-07, 9.2637e-01, 9.9994e-01, 6.8571e-04,\n",
            "         9.3886e-01, 3.6040e-06, 9.8427e-01, 4.6051e-02],\n",
            "        [1.0188e-06, 9.5642e-01, 2.9421e-04, 1.1614e-01, 7.4354e-01, 5.2162e-08,\n",
            "         7.0881e-05, 5.3409e-09, 9.9950e-01, 8.7828e-01],\n",
            "        [4.5065e-08, 9.9670e-01, 6.2356e-02, 9.9997e-01, 9.9719e-01, 1.1130e-06,\n",
            "         1.6907e-04, 4.4886e-04, 1.0000e+00, 1.4370e-01],\n",
            "        [4.1909e-01, 6.7792e-02, 1.6873e-08, 9.9999e-01, 9.9127e-01, 2.4521e-04,\n",
            "         7.6991e-02, 9.2031e-08, 9.9988e-01, 3.6388e-02],\n",
            "        [7.9358e-10, 5.6261e-01, 2.8737e-07, 9.9962e-01, 7.3277e-05, 6.5152e-07,\n",
            "         1.2966e-02, 4.2748e-01, 1.0000e+00, 6.9184e-08],\n",
            "        [1.8068e-08, 1.6746e-05, 1.1121e-06, 9.9938e-01, 9.9987e-01, 2.0469e-08,\n",
            "         9.9998e-01, 1.5146e-06, 4.0451e-01, 1.3129e-04],\n",
            "        [5.4188e-07, 1.4377e-05, 1.8073e-09, 9.8345e-01, 1.0000e+00, 4.7153e-04,\n",
            "         6.6416e-01, 6.7913e-02, 9.9999e-01, 3.9734e-04],\n",
            "        [1.6337e-01, 1.0619e-03, 6.1987e-02, 9.9996e-01, 9.9897e-01, 5.2720e-12,\n",
            "         9.5828e-01, 3.3703e-01, 5.1929e-02, 9.8956e-01],\n",
            "        [2.0297e-07, 1.2901e-04, 6.0419e-01, 9.4287e-01, 9.9990e-01, 7.4068e-04,\n",
            "         9.9984e-01, 2.4511e-01, 7.6910e-01, 6.9186e-09],\n",
            "        [3.4258e-04, 9.4419e-01, 1.2929e-05, 1.5687e-01, 9.9999e-01, 2.2763e-04,\n",
            "         2.9061e-04, 1.3616e-01, 9.9577e-01, 7.3192e-02],\n",
            "        [1.6171e-02, 7.4607e-01, 1.7657e-04, 6.3236e-01, 5.3291e-03, 2.4158e-01,\n",
            "         9.9339e-01, 3.4262e-02, 9.9668e-01, 2.5048e-07],\n",
            "        [4.7644e-06, 9.7909e-01, 2.5877e-04, 9.7978e-01, 9.9974e-01, 4.1637e-03,\n",
            "         5.8951e-06, 6.2776e-01, 1.0000e+00, 7.2390e-06],\n",
            "        [5.7840e-05, 8.8156e-03, 1.0657e-05, 9.9999e-01, 9.9689e-01, 4.8615e-05,\n",
            "         9.9940e-01, 4.5447e-01, 9.9996e-01, 3.5891e-05],\n",
            "        [6.2676e-12, 2.9561e-07, 2.8309e-07, 4.4276e-03, 1.0000e+00, 2.9676e-01,\n",
            "         9.9078e-01, 6.6561e-08, 1.0000e+00, 1.6856e-01],\n",
            "        [3.1248e-04, 2.3752e-04, 2.3443e-06, 9.6147e-01, 3.7732e-01, 5.8165e-05,\n",
            "         7.8753e-01, 2.8499e-06, 9.9981e-01, 3.5014e-01],\n",
            "        [1.9112e-06, 3.6034e-06, 4.1973e-03, 9.9972e-01, 6.5976e-01, 1.0532e-06,\n",
            "         9.9998e-01, 5.2067e-06, 9.1569e-01, 7.7865e-04],\n",
            "        [5.2283e-09, 1.0099e-03, 1.1590e-02, 9.9318e-01, 9.9997e-01, 3.0915e-06,\n",
            "         9.9997e-01, 1.9587e-04, 7.4407e-01, 4.1801e-04],\n",
            "        [4.5958e-02, 1.5558e-02, 7.2406e-04, 1.0000e+00, 9.9575e-01, 1.6374e-07,\n",
            "         2.7973e-01, 1.1533e-02, 1.0000e+00, 7.1425e-09],\n",
            "        [3.3186e-02, 9.9995e-01, 8.7567e-01, 4.1532e-01, 2.4643e-01, 5.3107e-09,\n",
            "         9.8384e-01, 9.3272e-01, 1.0000e+00, 3.6668e-05],\n",
            "        [5.6956e-04, 1.1555e-01, 2.0867e-02, 1.0000e+00, 1.3349e-04, 1.4315e-05,\n",
            "         3.9002e-02, 4.2337e-01, 1.0000e+00, 1.5086e-06],\n",
            "        [5.2078e-06, 9.9911e-01, 1.7930e-01, 5.5533e-01, 3.5749e-06, 9.3399e-03,\n",
            "         5.2707e-08, 9.8295e-06, 1.0000e+00, 5.0791e-06],\n",
            "        [9.4641e-05, 9.3440e-07, 6.3412e-07, 1.0000e+00, 1.0000e+00, 5.0335e-05,\n",
            "         9.4303e-01, 4.5195e-02, 9.9606e-01, 4.9578e-03],\n",
            "        [8.2211e-06, 2.0066e-03, 5.4484e-09, 7.7336e-03, 1.0000e+00, 6.3845e-02,\n",
            "         1.8197e-04, 5.9710e-09, 1.0000e+00, 5.1014e-04],\n",
            "        [4.4196e-13, 1.5382e-03, 2.7139e-07, 9.9414e-01, 8.1021e-01, 1.3633e-05,\n",
            "         6.5966e-01, 2.1213e-08, 9.9897e-01, 4.5705e-06],\n",
            "        [6.3036e-01, 2.7762e-05, 3.0250e-02, 9.9557e-01, 6.6082e-02, 4.1287e-06,\n",
            "         9.0304e-02, 4.4631e-05, 1.0000e+00, 5.8953e-12],\n",
            "        [7.4163e-07, 9.9994e-01, 4.0379e-04, 8.6733e-01, 9.7718e-01, 1.6513e-04,\n",
            "         9.1925e-01, 2.5933e-05, 9.9761e-01, 1.4931e-05],\n",
            "        [2.9519e-07, 5.5386e-02, 9.4576e-01, 1.0000e+00, 9.9833e-01, 4.3364e-09,\n",
            "         9.9962e-01, 9.9996e-01, 9.9901e-01, 2.2948e-04],\n",
            "        [5.3682e-07, 2.9536e-01, 1.3251e-01, 1.0000e+00, 9.9848e-01, 1.1018e-09,\n",
            "         9.8783e-01, 5.3098e-05, 1.0000e+00, 3.0975e-06],\n",
            "        [8.2489e-06, 4.3155e-02, 3.5399e-05, 1.0000e+00, 8.0336e-01, 3.4471e-08,\n",
            "         9.9943e-01, 1.4558e-08, 9.9998e-01, 6.1663e-02],\n",
            "        [4.9798e-05, 1.3289e-03, 5.1700e-02, 4.5953e-01, 6.4337e-03, 8.2638e-06,\n",
            "         9.8819e-01, 3.5387e-03, 8.2738e-01, 4.2995e-03],\n",
            "        [2.7907e-08, 7.0253e-04, 1.1034e-03, 1.0000e+00, 9.8537e-01, 1.7670e-04,\n",
            "         7.9103e-01, 1.2809e-03, 9.9352e-01, 1.2214e-05],\n",
            "        [1.1091e-06, 8.6672e-01, 1.6814e-01, 9.9996e-01, 2.0115e-02, 5.8740e-07,\n",
            "         6.9430e-01, 9.4671e-01, 9.9770e-01, 6.5613e-05],\n",
            "        [4.5023e-09, 9.9684e-01, 2.5857e-02, 3.8445e-03, 7.4452e-01, 3.6007e-08,\n",
            "         9.6530e-01, 1.3525e-02, 9.9895e-01, 9.1511e-10],\n",
            "        [6.0781e-04, 8.9364e-04, 1.9045e-09, 9.9169e-01, 1.0000e+00, 3.6805e-02,\n",
            "         9.8403e-01, 1.0747e-01, 9.9958e-01, 1.6261e-05],\n",
            "        [2.1306e-05, 7.2314e-01, 7.4842e-06, 8.7816e-01, 9.9806e-01, 8.5124e-05,\n",
            "         4.7449e-01, 3.7068e-03, 9.9983e-01, 3.7179e-03],\n",
            "        [6.2519e-01, 8.9798e-01, 4.6809e-05, 9.7703e-01, 4.9052e-01, 4.9545e-02,\n",
            "         1.0000e+00, 2.2317e-08, 4.8351e-01, 2.3847e-10],\n",
            "        [3.7605e-03, 1.3220e-03, 2.8855e-07, 9.9984e-01, 9.9192e-01, 2.4985e-02,\n",
            "         9.0197e-02, 2.2361e-03, 1.0000e+00, 1.1985e-04],\n",
            "        [1.3648e-03, 9.8284e-01, 2.7565e-04, 9.8514e-01, 9.4617e-01, 2.8230e-06,\n",
            "         9.8115e-01, 3.5886e-04, 9.9998e-01, 9.8683e-05],\n",
            "        [8.1033e-03, 1.9933e-03, 3.7494e-04, 9.9287e-01, 8.4536e-01, 8.8319e-01,\n",
            "         8.6658e-05, 4.4553e-01, 1.0000e+00, 2.5098e-05],\n",
            "        [1.5721e-02, 2.4940e-06, 2.7817e-04, 1.0000e+00, 9.9741e-01, 1.5424e-08,\n",
            "         9.9997e-01, 1.3795e-03, 2.5524e-01, 1.5715e-07],\n",
            "        [6.0318e-05, 7.0250e-05, 3.7443e-02, 9.9999e-01, 2.2430e-04, 1.1405e-09,\n",
            "         1.0000e+00, 2.0629e-07, 1.0000e+00, 8.5170e-07],\n",
            "        [8.1581e-07, 9.9983e-01, 9.9411e-01, 1.8333e-02, 1.8835e-02, 2.0554e-06,\n",
            "         1.3414e-02, 2.9912e-03, 1.0000e+00, 2.7002e-06],\n",
            "        [1.4280e-10, 9.9997e-01, 1.0361e-03, 9.9953e-01, 1.8774e-04, 2.7954e-01,\n",
            "         7.1391e-01, 2.2239e-03, 1.0000e+00, 2.9051e-09],\n",
            "        [1.3813e-07, 9.7821e-01, 9.8369e-01, 9.2041e-01, 1.1617e-04, 3.8544e-05,\n",
            "         8.9918e-01, 2.4580e-04, 1.0000e+00, 4.6540e-11],\n",
            "        [2.8377e-04, 9.9567e-02, 1.3428e-01, 9.9999e-01, 4.4867e-01, 7.8383e-04,\n",
            "         9.9968e-01, 1.4509e-02, 9.7695e-01, 3.8573e-09],\n",
            "        [2.3398e-08, 1.9929e-04, 9.7039e-05, 3.2893e-01, 9.9923e-01, 2.8342e-07,\n",
            "         9.9953e-01, 1.5314e-01, 9.9485e-01, 3.1049e-06],\n",
            "        [1.5682e-06, 2.5083e-03, 2.2174e-01, 1.0000e+00, 7.4963e-01, 4.8390e-08,\n",
            "         9.9843e-01, 8.4803e-06, 9.9984e-01, 2.8317e-03],\n",
            "        [3.8077e-04, 9.9965e-01, 4.1156e-02, 8.1180e-01, 9.9928e-01, 9.1557e-06,\n",
            "         9.8173e-01, 7.2391e-04, 1.0000e+00, 2.9344e-02],\n",
            "        [3.8828e-11, 4.9303e-05, 2.2409e-05, 1.0000e+00, 9.7996e-01, 7.1913e-05,\n",
            "         1.0000e+00, 5.1021e-08, 9.9819e-01, 8.4524e-02],\n",
            "        [5.0218e-08, 1.3880e-01, 1.4269e-05, 1.0000e+00, 9.3268e-01, 3.5693e-07,\n",
            "         5.7708e-01, 4.7367e-01, 9.9997e-01, 5.2757e-06],\n",
            "        [1.0993e-05, 1.0600e-01, 4.3558e-01, 8.7302e-01, 9.9490e-01, 3.3952e-09,\n",
            "         1.3329e-01, 8.9352e-08, 9.9999e-01, 1.8299e-04],\n",
            "        [6.1811e-09, 9.2420e-02, 7.7650e-01, 9.9995e-01, 1.2882e-05, 6.3106e-04,\n",
            "         2.3928e-01, 1.3466e-02, 9.9999e-01, 4.3329e-07],\n",
            "        [1.4637e-03, 6.4793e-01, 4.6984e-07, 9.9956e-01, 9.9999e-01, 1.9785e-04,\n",
            "         7.6355e-05, 8.2960e-04, 1.0000e+00, 7.4237e-01],\n",
            "        [1.6836e-11, 8.2395e-02, 1.5336e-03, 9.9875e-01, 9.8945e-01, 7.3206e-10,\n",
            "         1.6709e-02, 9.9854e-01, 9.8683e-01, 5.1114e-02],\n",
            "        [1.3546e-05, 3.7278e-05, 5.3151e-02, 1.0000e+00, 8.6057e-01, 2.9267e-09,\n",
            "         8.4029e-01, 2.9275e-05, 9.9998e-01, 2.5974e-03],\n",
            "        [2.3600e-04, 1.4395e-06, 1.5242e-09, 9.9981e-01, 1.0000e+00, 1.4888e-01,\n",
            "         9.9959e-01, 8.3275e-05, 9.9942e-01, 8.3597e-01],\n",
            "        [2.7630e-06, 1.4806e-02, 4.9340e-01, 1.0000e+00, 6.2773e-01, 1.2829e-04,\n",
            "         9.9910e-01, 3.1920e-02, 9.6688e-01, 3.0551e-05],\n",
            "        [9.0769e-07, 1.9022e-04, 4.3860e-05, 9.9992e-01, 1.0000e+00, 8.4843e-09,\n",
            "         9.3544e-01, 8.0946e-02, 9.9626e-01, 2.2831e-02]])\n",
            "torch.Size([64, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWBRiwkBnx0N",
        "colab_type": "code",
        "collapsed": true,
        "outputId": "30110ce2-49f7-4fd2-fc16-00b23bad2b0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2281
        }
      },
      "source": [
        "def softmax(x):\n",
        "    x = torch.exp(x)\n",
        "    values = []\n",
        "    print(x.shape)\n",
        "    for i in range(x.shape[0]):\n",
        "    x[i] = x[i]/torch.sum(x[i] , dim = 0)\n",
        "    print(x.shape)\n",
        "    return x\n",
        "\n",
        "pred = softmax(prediction)\n",
        "print(pred)\n",
        "print(pred[0].sum(dim = 0))"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 10])\n",
            "torch.Size([64, 10])\n",
            "tensor([[0.0659, 0.0660, 0.0659, 0.1771, 0.1791, 0.0660, 0.0660, 0.0686, 0.1791,\n",
            "         0.0662],\n",
            "        [0.0611, 0.1348, 0.0634, 0.1658, 0.1616, 0.0615, 0.0634, 0.0611, 0.1661,\n",
            "         0.0611],\n",
            "        [0.0759, 0.0781, 0.0762, 0.1751, 0.0833, 0.0759, 0.0770, 0.0760, 0.2063,\n",
            "         0.0759],\n",
            "        [0.0742, 0.0743, 0.0754, 0.0750, 0.1952, 0.0742, 0.0742, 0.0742, 0.2017,\n",
            "         0.0816],\n",
            "        [0.0592, 0.0593, 0.0592, 0.1610, 0.1610, 0.0593, 0.1610, 0.0592, 0.1610,\n",
            "         0.0598],\n",
            "        [0.0612, 0.0627, 0.0612, 0.0912, 0.1656, 0.1032, 0.1662, 0.0612, 0.1662,\n",
            "         0.0613],\n",
            "        [0.0605, 0.0605, 0.0605, 0.1528, 0.1645, 0.0606, 0.1547, 0.0605, 0.1619,\n",
            "         0.0634],\n",
            "        [0.0627, 0.1631, 0.0627, 0.0704, 0.1318, 0.0627, 0.0627, 0.0627, 0.1703,\n",
            "         0.1509],\n",
            "        [0.0586, 0.1587, 0.0623, 0.1592, 0.1587, 0.0586, 0.0586, 0.0586, 0.1592,\n",
            "         0.0676],\n",
            "        [0.0960, 0.0676, 0.0631, 0.1716, 0.1701, 0.0632, 0.0682, 0.0631, 0.1716,\n",
            "         0.0655],\n",
            "        [0.0679, 0.1191, 0.0679, 0.1844, 0.0679, 0.0679, 0.0687, 0.1040, 0.1844,\n",
            "         0.0679],\n",
            "        [0.0639, 0.0639, 0.0639, 0.1736, 0.1737, 0.0639, 0.1737, 0.0639, 0.0957,\n",
            "         0.0639],\n",
            "        [0.0620, 0.0620, 0.0620, 0.1658, 0.1686, 0.0620, 0.1205, 0.0664, 0.1686,\n",
            "         0.0620],\n",
            "        [0.0676, 0.0574, 0.0611, 0.1560, 0.1558, 0.0574, 0.1496, 0.0804, 0.0604,\n",
            "         0.1544],\n",
            "        [0.0579, 0.0579, 0.1060, 0.1487, 0.1574, 0.0579, 0.1574, 0.0740, 0.1250,\n",
            "         0.0579],\n",
            "        [0.0650, 0.1671, 0.0650, 0.0760, 0.1766, 0.0650, 0.0650, 0.0745, 0.1759,\n",
            "         0.0699],\n",
            "        [0.0646, 0.1341, 0.0636, 0.1196, 0.0639, 0.0809, 0.1717, 0.0658, 0.1722,\n",
            "         0.0636],\n",
            "        [0.0567, 0.1509, 0.0567, 0.1510, 0.1541, 0.0569, 0.0567, 0.1062, 0.1541,\n",
            "         0.0567],\n",
            "        [0.0573, 0.0578, 0.0573, 0.1558, 0.1553, 0.0573, 0.1557, 0.0903, 0.1558,\n",
            "         0.0573],\n",
            "        [0.0638, 0.0638, 0.0638, 0.0641, 0.1735, 0.0859, 0.1720, 0.0638, 0.1735,\n",
            "         0.0756],\n",
            "        [0.0649, 0.0649, 0.0649, 0.1697, 0.0946, 0.0649, 0.1426, 0.0649, 0.1764,\n",
            "         0.0921],\n",
            "        [0.0630, 0.0630, 0.0633, 0.1712, 0.1219, 0.0630, 0.1712, 0.0630, 0.1574,\n",
            "         0.0630],\n",
            "        [0.0615, 0.0616, 0.0622, 0.1661, 0.1672, 0.0615, 0.1672, 0.0615, 0.1295,\n",
            "         0.0615],\n",
            "        [0.0674, 0.0654, 0.0644, 0.1749, 0.1742, 0.0643, 0.0851, 0.0651, 0.1749,\n",
            "         0.0643],\n",
            "        [0.0548, 0.1440, 0.1271, 0.0802, 0.0678, 0.0530, 0.1417, 0.1346, 0.1440,\n",
            "         0.0530],\n",
            "        [0.0707, 0.0793, 0.0722, 0.1921, 0.0707, 0.0707, 0.0735, 0.1079, 0.1921,\n",
            "         0.0707],\n",
            "        [0.0695, 0.1888, 0.0832, 0.1212, 0.0695, 0.0702, 0.0695, 0.0695, 0.1890,\n",
            "         0.0695],\n",
            "        [0.0597, 0.0597, 0.0597, 0.1622, 0.1622, 0.0597, 0.1532, 0.0624, 0.1615,\n",
            "         0.0600],\n",
            "        [0.0740, 0.0742, 0.0740, 0.0746, 0.2012, 0.0789, 0.0740, 0.0740, 0.2012,\n",
            "         0.0740],\n",
            "        [0.0641, 0.0642, 0.0641, 0.1732, 0.1441, 0.0641, 0.1240, 0.0641, 0.1740,\n",
            "         0.0641],\n",
            "        [0.1296, 0.0690, 0.0711, 0.1867, 0.0737, 0.0690, 0.0755, 0.0690, 0.1875,\n",
            "         0.0690],\n",
            "        [0.0556, 0.1512, 0.0557, 0.1324, 0.1478, 0.0556, 0.1395, 0.0556, 0.1509,\n",
            "         0.0556],\n",
            "        [0.0495, 0.0523, 0.1274, 0.1345, 0.1342, 0.0495, 0.1344, 0.1345, 0.1343,\n",
            "         0.0495],\n",
            "        [0.0577, 0.0776, 0.0659, 0.1569, 0.1567, 0.0577, 0.1550, 0.0577, 0.1569,\n",
            "         0.0577],\n",
            "        [0.0606, 0.0633, 0.0606, 0.1648, 0.1354, 0.0606, 0.1647, 0.0606, 0.1648,\n",
            "         0.0645],\n",
            "        [0.0734, 0.0735, 0.0773, 0.1162, 0.0739, 0.0734, 0.1972, 0.0737, 0.1679,\n",
            "         0.0737],\n",
            "        [0.0613, 0.0614, 0.0614, 0.1667, 0.1643, 0.0613, 0.1353, 0.0614, 0.1656,\n",
            "         0.0613],\n",
            "        [0.0568, 0.1352, 0.0673, 0.1545, 0.0580, 0.0568, 0.1138, 0.1465, 0.1542,\n",
            "         0.0568],\n",
            "        [0.0617, 0.1673, 0.0633, 0.0620, 0.1300, 0.0617, 0.1621, 0.0626, 0.1676,\n",
            "         0.0617],\n",
            "        [0.0590, 0.0590, 0.0590, 0.1590, 0.1603, 0.0612, 0.1577, 0.0657, 0.1602,\n",
            "         0.0590],\n",
            "        [0.0606, 0.1248, 0.0606, 0.1457, 0.1643, 0.0606, 0.0973, 0.0608, 0.1646,\n",
            "         0.0608],\n",
            "        [0.1099, 0.1444, 0.0588, 0.1562, 0.0960, 0.0618, 0.1599, 0.0588, 0.0954,\n",
            "         0.0588],\n",
            "        [0.0658, 0.0656, 0.0655, 0.1781, 0.1767, 0.0672, 0.0717, 0.0657, 0.1781,\n",
            "         0.0655],\n",
            "        [0.0547, 0.1459, 0.0546, 0.1462, 0.1406, 0.0546, 0.1457, 0.0546, 0.1484,\n",
            "         0.0546],\n",
            "        [0.0602, 0.0599, 0.0598, 0.1613, 0.1391, 0.1445, 0.0598, 0.0933, 0.1624,\n",
            "         0.0598],\n",
            "        [0.0657, 0.0647, 0.0647, 0.1759, 0.1754, 0.0647, 0.1759, 0.0648, 0.0835,\n",
            "         0.0647],\n",
            "        [0.0658, 0.0658, 0.0683, 0.1789, 0.0658, 0.0658, 0.1789, 0.0658, 0.1789,\n",
            "         0.0658],\n",
            "        [0.0658, 0.1789, 0.1779, 0.0670, 0.0671, 0.0658, 0.0667, 0.0660, 0.1789,\n",
            "         0.0658],\n",
            "        [0.0605, 0.1645, 0.0606, 0.1645, 0.0605, 0.0800, 0.1236, 0.0607, 0.1645,\n",
            "         0.0605],\n",
            "        [0.0555, 0.1476, 0.1484, 0.1393, 0.0555, 0.0555, 0.1364, 0.0555, 0.1508,\n",
            "         0.0555],\n",
            "        [0.0628, 0.0694, 0.0718, 0.1707, 0.0984, 0.0629, 0.1707, 0.0637, 0.1668,\n",
            "         0.0628],\n",
            "        [0.0637, 0.0637, 0.0637, 0.0885, 0.1731, 0.0637, 0.1731, 0.0743, 0.1723,\n",
            "         0.0637],\n",
            "        [0.0605, 0.0607, 0.0756, 0.1645, 0.1281, 0.0605, 0.1643, 0.0605, 0.1645,\n",
            "         0.0607],\n",
            "        [0.0551, 0.1497, 0.0574, 0.1241, 0.1497, 0.0551, 0.1471, 0.0551, 0.1498,\n",
            "         0.0568],\n",
            "        [0.0592, 0.0592, 0.0592, 0.1608, 0.1576, 0.0592, 0.1608, 0.0592, 0.1605,\n",
            "         0.0644],\n",
            "        [0.0606, 0.0696, 0.0606, 0.1646, 0.1539, 0.0606, 0.1078, 0.0972, 0.1646,\n",
            "         0.0606],\n",
            "        [0.0640, 0.0712, 0.0990, 0.1533, 0.1732, 0.0640, 0.0732, 0.0640, 0.1741,\n",
            "         0.0640],\n",
            "        [0.0667, 0.0732, 0.1450, 0.1813, 0.0667, 0.0667, 0.0847, 0.0676, 0.1813,\n",
            "         0.0667],\n",
            "        [0.0583, 0.1113, 0.0582, 0.1583, 0.1583, 0.0583, 0.0583, 0.0583, 0.1583,\n",
            "         0.1224],\n",
            "        [0.0590, 0.0640, 0.0591, 0.1601, 0.1586, 0.0590, 0.0600, 0.1601, 0.1582,\n",
            "         0.0621],\n",
            "        [0.0618, 0.0618, 0.0652, 0.1681, 0.1462, 0.0618, 0.1432, 0.0618, 0.1680,\n",
            "         0.0620],\n",
            "        [0.0545, 0.0545, 0.0545, 0.1482, 0.1482, 0.0633, 0.1482, 0.0545, 0.1481,\n",
            "         0.1258],\n",
            "        [0.0602, 0.0611, 0.0985, 0.1635, 0.1127, 0.0602, 0.1634, 0.0621, 0.1582,\n",
            "         0.0602],\n",
            "        [0.0595, 0.0595, 0.0595, 0.1618, 0.1618, 0.0595, 0.1517, 0.0645, 0.1612,\n",
            "         0.0609]])\n",
            "tensor(1.0000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uw93JEaO0Pg0",
        "colab_type": "text"
      },
      "source": [
        "In pytorch it is a convention to assign criterion = nn.loss() class. <br/>\n",
        "Eg: - criterion = nn.CrossEntropyLoss()<br/>\n",
        "So the expected input to these loss function is the logits or the scores and not the softmax probablities.\n",
        "Eg: given below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5E--ABQxkpB",
        "colab_type": "code",
        "outputId": "9a715bfc-9c04-4880-d564-db94434e4164",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# New way of creating a sequential model\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "model = nn.Sequential(nn.Linear(784 , 128),\n",
        "                   nn.ReLU(),\n",
        "                   nn.Linear(128 , 64),\n",
        "                   nn.ReLU(),\n",
        "                   nn.Linear(64,10))\n",
        "\n",
        "images , labels = next(iter(trainloader))\n",
        "images = images.reshape(images.shape[0] , -1)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "logits = model(images)\n",
        "# so we see we are passing logits i.e. original values rather than the softmax probabilities\n",
        "loss = criterion(logits , labels)\n",
        "print(loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2.3073, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVeDbnnL5xlm",
        "colab_type": "text"
      },
      "source": [
        "Pytorch has this really great class named autograd which keeps track of the tensor operations performed by us and when you tell it to do a backwards pass it will go backwards through each of these operations and calculate gradients wrt the input parameters.<br/>\n",
        "In general we need to tell pytorch that we want to use auto grad on a specific tensor.\n",
        "Eg: - "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRLZL0EW6q1h",
        "colab_type": "code",
        "outputId": "b12f5c37-4372-441a-8206-2e50da3dd122",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "a = torch.tensor([1,2,3] , requires_grad=True , dtype = torch.float64)\n",
        "print(a)\n",
        "# this will tell pytorch to track the operations of this tensor and it can compute its gradient whenever needed.\n",
        "# you can also do it using\n",
        "with torch.no_grad():\n",
        "    b = torch.tensor([1,2,3] , dtype = torch.float64)\n",
        "print(b.requires_grad)\n",
        "\n",
        "# you can also do it globally for all the variables using\n",
        "# torch.set_grad_enabled(True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1., 2., 3.], dtype=torch.float64, requires_grad=True)\n",
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tupXhSjp9niF",
        "colab_type": "code",
        "outputId": "0687758e-30ea-46e1-c2d0-b97e7dc5fd79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# Using autograd to compute the gradients\n",
        "# we just do a variable.backward() if we want to compute its graident\n",
        "a = torch.tensor([1,2,3] , requires_grad=True , dtype = torch.float64)\n",
        "y = (a ** 2).sum(dim = 0)\n",
        "# we have to do sum because we can perform backward pass only on a scalar value\n",
        "print(y)\n",
        "print(\"Gradient without performing the backward pass {}\".format(a.grad))\n",
        "y.backward()\n",
        "print(\"Gradient after performing the backward pass {}\".format(a.grad.numpy()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(14., dtype=torch.float64, grad_fn=<SumBackward2>)\n",
            "Gradient without performing the backward pass None\n",
            "Gradient after performing the backward pass [2. 4. 6.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOnSY_-aD--o",
        "colab_type": "text"
      },
      "source": [
        "Once we have our gradients we need optimizers to update the weights by using the gradients.<br/>\n",
        "We need to clear the gradients because pytorch accumulates gradients and we do it using\n",
        "**optimizer.zero_grad() before every training process**.<br/>\n",
        "A step with the optimizer updates the weights."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XLhtz-g_8Ec",
        "colab_type": "code",
        "outputId": "c81073bd-4292-48ce-eefa-544f74d562d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        }
      },
      "source": [
        "# incase of neural networks pytorch automatically computes the gradient of weights by using autograd to note their computations\n",
        "print(\"Gradients of the weights before backward pass {}\".format(model[0].weight.grad))\n",
        "loss.backward()\n",
        "print(\"Gradients of the weights after backward pass {}\".format(model[0].weight.grad))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gradients of the weights before backward pass None\n",
            "Gradients of the weights after backward pass tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xlm6K4CeJTb4",
        "colab_type": "code",
        "outputId": "08f85696-64b2-457c-97ce-19ebfbfc76fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "collapsed": true
      },
      "source": [
        "import torch.optim as optim\n",
        "optimizer = optim.SGD(model.parameters() , lr = 1e-3)\n",
        "optimizer.zero_grad()\n",
        "print(\"weights before stepping\" , model[0].weight)\n",
        "optimizer.step()\n",
        "print(\"Weights after stepping\" , model[0].weight)\n",
        "# not much of a difference since our graident was different"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "weights before stepping Parameter containing:\n",
            "tensor([[-0.0308, -0.0258,  0.0248,  ..., -0.0216,  0.0269, -0.0173],\n",
            "        [ 0.0106, -0.0249, -0.0019,  ..., -0.0135, -0.0078, -0.0038],\n",
            "        [-0.0121, -0.0326,  0.0062,  ...,  0.0217, -0.0090,  0.0092],\n",
            "        ...,\n",
            "        [-0.0030, -0.0177, -0.0318,  ...,  0.0315, -0.0259,  0.0139],\n",
            "        [-0.0119,  0.0120,  0.0171,  ..., -0.0354, -0.0159, -0.0330],\n",
            "        [ 0.0293,  0.0183, -0.0165,  ..., -0.0191,  0.0130,  0.0084]],\n",
            "       requires_grad=True)\n",
            "Weights after stepping Parameter containing:\n",
            "tensor([[-0.0308, -0.0258,  0.0248,  ..., -0.0216,  0.0269, -0.0173],\n",
            "        [ 0.0106, -0.0249, -0.0019,  ..., -0.0135, -0.0078, -0.0038],\n",
            "        [-0.0121, -0.0326,  0.0062,  ...,  0.0217, -0.0090,  0.0092],\n",
            "        ...,\n",
            "        [-0.0030, -0.0177, -0.0318,  ...,  0.0315, -0.0259,  0.0139],\n",
            "        [-0.0119,  0.0120,  0.0171,  ..., -0.0354, -0.0159, -0.0330],\n",
            "        [ 0.0293,  0.0183, -0.0165,  ..., -0.0191,  0.0130,  0.0084]],\n",
            "       requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbZCm45qZRhd",
        "colab_type": "text"
      },
      "source": [
        "Since for validation we dont need to train there is no need of having autograd track all the variables. So we do <br/>\n",
        "with torch.no_grad(): <br/>\n",
        "for images, labels in testloader <br/>\n",
        " We only need enumerate if we want to keep track of the number of epochs for verbosity.<br/>\n",
        "Put the validation loop inside the with segment. It saves us some computation.<br/>\n",
        "The general idea is after each forward pass of the epoch we want to calculate our validation accuracy. Eg: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5Da3LqLN0tH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkTzfJFae5QL",
        "colab_type": "text"
      },
      "source": [
        "Using dropouts<br/>\n",
        "Dont use dropout in the last layer.<br/>\n",
        "We want to do use dropout only for training and not for testing hence we have to use something known as model.eval().<br/>\n",
        "It turns of dropouts when we are doing validation,testing or even predictions.<br/>\n",
        "Then again to set our model back to training mode we use model.train(). This is particularly important when we are calculating validation accuracy since we will be training first then calculating the accuracy for that epoch and again doing the training for the next epoch so if we dont do model.train() our model wont consider dropouts while training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtblrKgxe7v6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}