{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SarthakNarayan/DL-and-ML/blob/master/googlecolab/Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2y5PCw7GKlOY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "def sigmoid(x):\n",
        "    activation = 1/(1 + torch.exp(-x))\n",
        "    return activation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbYjgqdNOBGs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.manual_seed(23)\n",
        "weights = torch.randn((5,1))\n",
        "print(weights)\n",
        "print(weights.shape)\n",
        "weights = torch.reshape(weights , (1,5))\n",
        "print(\"sum of all the weights {}\".format(torch.sum(weights)))\n",
        "print(\"sum of all the weights {}\".format(weights.sum()))\n",
        "features = torch.randn((5,1))\n",
        "bias = torch.randn((1,1))\n",
        "# More advisable to use mm since it is strict about the shapes whereas matmul supports broadcasting\n",
        "y_hat = torch.add(torch.mm(weights,features),bias)\n",
        "print(\"y_hat before activation\",y_hat)\n",
        "y_hat = sigmoid(y_hat)\n",
        "print(\"y_hat after activation\",y_hat)\n",
        "print(\"so we see sigmoid converts any value to between 1 and 0\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcx-L8UdPk96",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# normal * does element wise multiplication\n",
        "print(torch.tensor([1,2,3])*torch.tensor([1,2,3]))\n",
        "# torch.dot performs element wise multiplication and sums them\n",
        "print(torch.dot(torch.tensor([1,2,3]),torch.tensor([1,2,3])))\n",
        "a = torch.tensor([[1,2,3] , [1,2,3]])\n",
        "print(\"Sum along the columns {}\".format(torch.sum(a , dim = 0).numpy()))\n",
        "print(\"Sum along the rows {}\".format(torch.sum(a , dim = 1).numpy()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Si7s-0trRBT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = torch.tensor([[1,2,3],[1,2,3]])\n",
        "print(a)\n",
        "print(a[0][0].item())\n",
        "# .item() only works for a scalar value and not any array\n",
        "# so a[0].item() will also not work"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xdy6ywpjYnvT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# multilayer perceptron\n",
        "torch.manual_seed(23)\n",
        "# w*x + b\n",
        "def multilayer_perceptron(no_of_features,no_of_hidden_units,no_output_nodes):\n",
        "    x = torch.randn((no_of_features , 1))\n",
        "    weights = torch.randn((no_of_hidden_units , no_of_features))\n",
        "    bias = torch.randn((no_of_hidden_units , 1))\n",
        "    h12 = torch.add(torch.mm(weights,x),bias)\n",
        "    print(h12)\n",
        "    h12 = sigmoid(h12)\n",
        "    print(h12)\n",
        "    weights = torch.randn((no_output_nodes , h12.shape[0]))\n",
        "    bias = torch.randn((no_output_nodes , 1))\n",
        "    h = torch.add(torch.mm(weights,h12),bias)\n",
        "    print(h)\n",
        "    y_hat = sigmoid(h)\n",
        "    print(y_hat)\n",
        "\n",
        "multilayer_perceptron(2,3,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ynTd0fnYxfV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# bridging numpy array with pytorch\n",
        "import numpy as np\n",
        "a = np.random.randn(1,2)\n",
        "print(a)\n",
        "b = torch.from_numpy(a)\n",
        "print(b)\n",
        "print(\"Back to numpy\")\n",
        "print(b.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Os0-94Hibfc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Using mnist data on my perceptron network\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor()])\n",
        "\n",
        "# to get the test set you set train = False\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "print(len(testset))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GYgW3DKjGO-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64,\n",
        "                                          shuffle=True)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64,\n",
        "                                         shuffle=True)\n",
        "print(\"Total number of batches {}\".format(len(testloader)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDmem8otjdP8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images , labels = next(iter(testloader))\n",
        "print(images.shape)\n",
        "images = images.reshape((64,-1))\n",
        "print(images.shape)\n",
        "torch.manual_seed(23)\n",
        "\n",
        "# x*w + b\n",
        "def multilayer_for_mnist(features,no_of_hidden_units,no_of_outputs):\n",
        "    x = features\n",
        "    w1 = torch.randn((features.shape[1] , no_of_hidden_units))\n",
        "    b1 = torch.randn((features.shape[0] , no_of_hidden_units))\n",
        "    h12 = torch.add(torch.matmul(x,w1) , b1)\n",
        "    h12 = sigmoid(h12)\n",
        "    w2 = torch.randn((h12.shape[1] , no_of_outputs))\n",
        "    b2 = torch.randn((h12.shape[0] , no_of_outputs))\n",
        "    h = torch.add(torch.matmul(h12,w2) , b2)\n",
        "    y_hat = sigmoid(h)\n",
        "    print(y_hat)\n",
        "    print(y_hat.shape)\n",
        "    return y_hat\n",
        "\n",
        "prediction = multilayer_for_mnist(images , 256 , 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWBRiwkBnx0N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def softmax(x):\n",
        "    x = torch.exp(x)\n",
        "    values = []\n",
        "    print(x.shape)\n",
        "    for i in range(x.shape[0]):\n",
        "        x[i] = x[i]/torch.sum(x[i] , dim = 0)\n",
        "    print(x.shape)\n",
        "    return x\n",
        "\n",
        "pred = softmax(prediction)\n",
        "print(pred)\n",
        "print(pred[0].sum(dim = 0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uw93JEaO0Pg0",
        "colab_type": "text"
      },
      "source": [
        "In pytorch it is a convention to assign criterion = nn.loss() class. <br/>\n",
        "Eg: - criterion = nn.CrossEntropyLoss()<br/>\n",
        "So the expected input to these loss function is the logits or the scores and not the softmax probablities.\n",
        "Eg: given below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5E--ABQxkpB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# New way of creating a sequential model\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "model = nn.Sequential(nn.Linear(784 , 128),\n",
        "                   nn.ReLU(),\n",
        "                   nn.Linear(128 , 64),\n",
        "                   nn.ReLU(),\n",
        "                   nn.Linear(64,10))\n",
        "\n",
        "images , labels = next(iter(trainloader))\n",
        "images = images.reshape(images.shape[0] , -1)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "logits = model(images)\n",
        "# so we see we are passing logits i.e. original values rather than the softmax probabilities\n",
        "loss = criterion(logits , labels)\n",
        "print(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVeDbnnL5xlm",
        "colab_type": "text"
      },
      "source": [
        "Pytorch has this really great class named autograd which keeps track of the tensor operations performed by us and when you tell it to do a backwards pass it will go backwards through each of these operations and calculate gradients wrt the input parameters.<br/>\n",
        "In general we need to tell pytorch that we want to use auto grad on a specific tensor.\n",
        "Eg: - "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRLZL0EW6q1h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = torch.tensor([1,2,3] , requires_grad=True , dtype = torch.float64)\n",
        "print(a)\n",
        "# this will tell pytorch to track the operations of this tensor and it can compute its gradient whenever needed.\n",
        "# you can also do it using\n",
        "with torch.no_grad():\n",
        "    b = torch.tensor([1,2,3] , dtype = torch.float64)\n",
        "print(b.requires_grad)\n",
        "\n",
        "# you can also do it globally for all the variables using\n",
        "# torch.set_grad_enabled(True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tupXhSjp9niF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Using autograd to compute the gradients\n",
        "# we just do a variable.backward() if we want to compute its graident\n",
        "a = torch.tensor([1,2,3] , requires_grad=True , dtype = torch.float64)\n",
        "y = (a ** 2).sum(dim = 0)\n",
        "# we have to do sum because we can perform backward pass only on a scalar value and not any vector\n",
        "print(y)\n",
        "print(\"Gradient without performing the backward pass {}\".format(a.grad))\n",
        "y.backward()\n",
        "print(\"Gradient after performing the backward pass {}\".format(a.grad.numpy()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOnSY_-aD--o",
        "colab_type": "text"
      },
      "source": [
        "Once we have our gradients we need optimizers to update the weights by using the gradients.<br/>\n",
        "We need to clear the gradients because pytorch accumulates gradients and we do it using\n",
        "**optimizer.zero_grad() before every training process**.<br/>\n",
        "A step with the optimizer updates the weights."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XLhtz-g_8Ec",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# incase of neural networks pytorch automatically computes the gradient of weights by using autograd to note their computations\n",
        "print(\"Gradients of the weights before backward pass {}\".format(model[0].weight.grad))\n",
        "loss.backward()\n",
        "print(\"Gradients of the weights after backward pass {}\".format(model[0].weight.grad))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xlm6K4CeJTb4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "optimizer = optim.SGD(model.parameters() , lr = 1e-3)\n",
        "optimizer.zero_grad()\n",
        "print(\"weights before stepping\" , model[0].weight)\n",
        "optimizer.step()\n",
        "print(\"Weights after stepping\" , model[0].weight)\n",
        "# not much of a difference since our graident was different"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbZCm45qZRhd",
        "colab_type": "text"
      },
      "source": [
        "Since for validation we dont need to train there is no need of having autograd track all the variables. So we do <br/>\n",
        "with torch.no_grad(): <br/>\n",
        "for images, labels in testloader <br/>\n",
        " We only need enumerate if we want to keep track of the number of epochs for verbosity.<br/>\n",
        "Put the validation loop inside the with segment. It saves us some computation.<br/>\n",
        "The general idea is after each forward pass of the epoch we want to calculate our validation accuracy. Eg: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5Da3LqLN0tH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Using dropouts in a model\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Network , self).__init__()\n",
        "        self.fc1 = nn.Linear(784 , 256)\n",
        "        self.fc2 = nn.Linear(256 , 128)\n",
        "        self.fc3 = nn.Linear(128 , 64)\n",
        "        self.fc4 = nn.Linear(64 , 10)\n",
        "        \n",
        "        self.dropout = nn.Dropout(p=0.2)\n",
        "    def forward(self , x):\n",
        "        x = x.reshape(x.shape[0] , -1)\n",
        "        x = self.dropout(F.relu(self.fc1(x)))\n",
        "        x = self.dropout(F.relu(self.fc2(x)))\n",
        "        x = self.dropout(F.relu(self.fc3(x)))\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "# Better of using GPU\n",
        "# To move the model and images back to CPU do .cpu() for the model and the images\n",
        "net = Network().cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkTzfJFae5QL",
        "colab_type": "text"
      },
      "source": [
        "Using dropouts<br/>\n",
        "Dont use dropout in the last layer.<br/>\n",
        "We want to do use dropout only for training and not for testing hence we have to use something known as model.eval().<br/>\n",
        "It turns of dropouts when we are doing validation,testing or even predictions.<br/>\n",
        "Then again to set our model back to training mode we use model.train(). This is particularly important when we are calculating validation accuracy since we will be training first then calculating the accuracy for that epoch and again doing the training for the next epoch so if we dont do model.train() our model wont consider dropouts while training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtblrKgxe7v6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calculating validation accuracy along with training\n",
        "num_epochs = 3\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters() , lr = 1e-3)\n",
        "for i in range(num_epochs):\n",
        "    running_loss = 0\n",
        "    counter = 0\n",
        "    for images , labels in trainloader:\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        optimizer.zero_grad()\n",
        "        logits = net(images)\n",
        "        loss = criterion(logits , labels)\n",
        "        running_loss += loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    # since you are calculating loss for the whole batch and not each image\n",
        "    print(\"Training Loss after {} epoch is {}\".format(i , (running_loss/len(trainloader))))\n",
        "    \n",
        "    net.eval()\n",
        "    correct = 0\n",
        "    accuracy = 0\n",
        "    for images_test , labels_test in testloader:\n",
        "        with torch.no_grad():\n",
        "            images_test = images_test.cuda()\n",
        "            labels_test = labels_test.cuda()\n",
        "            pred = net(images_test)\n",
        "            values , indices = torch.max(pred , 1)\n",
        "            for j in range(len(indices)):\n",
        "                if(indices[j] == labels_test[j]):\n",
        "                    correct = correct + 1\n",
        "    accuracy = (correct/len(testset))*100\n",
        "    # we can print validation loss if we want\n",
        "    print(\"Validation accuracy after {} epoch is {}\".format(i , accuracy))\n",
        "    net.train()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWMVZ_kn5NCF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# using torch.max()\n",
        "a = torch.tensor([[1,2,3],[1,2,3]])\n",
        "value , index = torch.max(a , 1)\n",
        "print(value,index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCi0TqzgEkMA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(net)\n",
        "# print(net.state_dict())\n",
        "print(net.state_dict().keys())\n",
        "# to see the weights and gradients of any layer\n",
        "print(net.fc1.weight)\n",
        "print(net.fc1.weight.grad)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcxWBxRcF4uT",
        "colab_type": "text"
      },
      "source": [
        "For loading datasets we use torchvision<br/>\n",
        "trainset = dataset.ImageFolder('path' , transform = transforms)<br/>\n",
        "It expects that different classes should be in different folders<br/>\n",
        "Dont play too much with the transforms of test data set.<br/>\n",
        "Most common transforms for both training and testing are random crop , resize , totensor \n",
        "and rotation,horizontal flip for training.\n",
        "\n",
        "**Transfer Learning**<br/>\n",
        "Most of the models are pretrained on input images of 224*224 also we will need to match the normalization. The means are [0.485 , 0.456 , 0.406] and std is [0.229 , 0.224 , 0.225]<br/>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8T6QY31yF2ki",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision import models,datasets,transforms\n",
        "transfer_model = models.densenet121(pretrained=True)\n",
        "print(transfer_model.state_dict().keys())\n",
        "# odict_keys means ordered dictionary keys \n",
        "print(\"\\n Classifier before changing \\n\" ,transfer_model.classifier)\n",
        "\n",
        "# we need to change the classifier with our own classifier\n",
        "from collections import OrderedDict\n",
        "'''\n",
        "OrderedDict preserves the order in which the keys are inserted. \n",
        "A regular dict doesn’t track the insertion order, \n",
        "and iterating it gives the values in an arbitrary order\n",
        "'''\n",
        "# you give sequential a list of operations and it will pass the tensor through it sequentially\n",
        "classifier = nn.Sequential(OrderedDict([\n",
        "    ('fc1' , nn.Linear(1024,500)),\n",
        "    ('relu' , nn.ReLU()),\n",
        "    ('output' , nn.Linear(500,10))\n",
        "#     10 is if u have 10 classes\n",
        "]))\n",
        "\n",
        "transfer_model.classifier = classifier\n",
        "print(\"\\n Classifier after changing \\n\" ,transfer_model.classifier)\n",
        "\n",
        "# another way of adding a classifier\n",
        "class AnotherClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AnotherClassifier , self).__init__()\n",
        "        self.fc1 = nn.Linear(1024 , 256)\n",
        "        self.fc2 = nn.Linear(256 , 128)\n",
        "        self.fc3 = nn.Linear(128 , 64)\n",
        "        self.fc4 = nn.Linear(64 , 10)       \n",
        "        self.dropout = nn.Dropout(p=0.2)\n",
        "        \n",
        "    def forward(self , x):\n",
        "        x = self.dropout(F.relu(self.fc1(x)))\n",
        "        x = self.dropout(F.relu(self.fc2(x)))\n",
        "        x = self.dropout(F.relu(self.fc3(x)))\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "    \n",
        "print(\"\\n Another way of adding the classifier \\n\")\n",
        "classifier = AnotherClassifier()\n",
        "transfer_model.classifier = classifier\n",
        "print(\"\\n Classifier after changing \\n\" ,transfer_model.classifier)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7nVkTFlPMeH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We need to retrain the classifier part and keep the feature part static\n",
        "# here param refers to the weights and biases since parameter class has the weights and biases\n",
        "for param in transfer_model.parameters():\n",
        "    param.requires_grad = False\n",
        "# This will make sure all the parameters are frozen and we dont compute their gradients hence making the execution faster\n",
        "# Since we only want to update the parameters of the classifier we will do \n",
        "optimizer = optim.Adam(transfer_model.classifier.parameters() , lr = 0.001)\n",
        "# this will leave the weights of the feature detector static and update weights and biases of the classifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guSP_ci1axYw",
        "colab_type": "text"
      },
      "source": [
        "# Tips\n",
        "##Watch those shapes<br/>\n",
        "In general, you'll want to check that the tensors going through your model and other code are the correct shapes. Make use of the .shape method during debugging and development.\n",
        "\n",
        "##A few things to check if your network isn't training appropriately\n",
        "Make sure you're clearing the gradients in the training loop with optimizer.zero_grad(). If you're doing a validation loop, be sure to set the network to evaluation mode with model.eval(), then back to training mode with model.train().\n",
        "\n",
        "##CUDA errors\n",
        "Sometimes you'll see this error:\n",
        "\n",
        "RuntimeError: Expected object of type torch.FloatTensor but found type torch.cuda.FloatTensor for argument #1 ‘mat1’\n",
        "\n",
        "You'll notice the second type is torch.cuda.FloatTensor, this means it's a tensor that has been moved to the GPU. It's expecting a tensor with type torch.FloatTensor, no .cuda there, which means the tensor should be on the CPU. PyTorch can only perform operations on tensors that are on the same device, so either both CPU or both GPU. If you're trying to run your network on the GPU, check to make sure you've moved the model and all necessary tensors to the GPU with .to(device) where device is either \"cuda\" or \"cpu\".\n",
        "\n",
        "##Data Normalization\n",
        "Data normalization make our model train and reach a minimum error, faster!\n",
        "\n",
        "Data normalization is typically done by subtracting the mean (the average of all pixel values) from each pixel, and then dividing the result by the standard deviation of all the pixel values. Sometimes you'll see an approximation here, where we use a mean and standard deviation of 0.5 to center the pixel values. \n",
        "\n",
        "## Using Validation loss\n",
        "Check for validation loss in each epoch and find if it is minimum than the previous one. If yes then save the weights of the model. Hence you will always have the best model weights. Make the initial minimum as infinity by using np.Inf.<br/>\n",
        "Before testing the model load it. Otherwise you will have a model which doesnt have the best validation accuracy.\n",
        "\n",
        "## Image augmentation\n",
        "transforms.compose is used for data augmentation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dmKHWSnbAhP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "print(\"Length of training dataset before splitting {}\".format(len(trainset)))\n",
        "trainset , validationset = torch.utils.data.random_split(trainset , [55000,5000])\n",
        "print(\"Length of training set {} and validation set {} after splitting\".format(len(trainset) , len(validationset)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKPlkn6QabMO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64,\n",
        "                                          shuffle=True)\n",
        "validationloader = torch.utils.data.DataLoader(validationset, batch_size=64,\n",
        "                                          shuffle=True)\n",
        "# to see the labels have been split \n",
        "images , labels = next(iter(validationloader))\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "print(labels[5])\n",
        "print(images.shape)\n",
        "# vary the first parameter to view the 64 images\n",
        "plt.imshow(images[5][0] , cmap = 'gray')\n",
        "plt.plot()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}