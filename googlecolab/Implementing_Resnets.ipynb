{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Implementing Resnets.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SarthakNarayan/DL-and-ML/blob/master/googlecolab/Implementing_Resnets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSf375yq5pTZ",
        "colab_type": "text"
      },
      "source": [
        "###Colors section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "481BnLVK5ozK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class color:\n",
        "    PURPLE = '\\033[95m'\n",
        "    CYAN = '\\033[96m'\n",
        "    DARKCYAN = '\\033[36m'\n",
        "    BLUE = '\\033[94m'\n",
        "    GREEN = '\\033[92m'\n",
        "    YELLOW = '\\033[93m'\n",
        "    RED = '\\033[91m'\n",
        "    BOLD = '\\033[1m'\n",
        "    UNDERLINE = '\\033[4m'\n",
        "    END = '\\033[0m'\n",
        "\n",
        "# print (color.GREEN + 'Hello World !' )\n",
        "# print(\"happens if u dont end it\")\n",
        "# print(color.END)\n",
        "# print(\"will not happen now\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2HAQWnY5pDJ",
        "colab_type": "text"
      },
      "source": [
        "###Imports Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7K9uLfPYjiw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lv7eDjkJT3dP",
        "colab_type": "text"
      },
      "source": [
        "##ResNet 50,101,152 architecture\n",
        "https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MmO772EnihC",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://www.codeproject.com/KB/AI/1248963/resnet.png)<br/>\n",
        "You can see the layer count on the top right hand corner.<br/>\n",
        "They use bottleneck blocks whereas as ResNet 18 and 34 uses basic blocks<br/>\n",
        "You can see number of blocks information below\n",
        "![alt text](https://cdn-images-1.medium.com/max/1600/1*aq0q7gCvuNUqnMHh4cpnIw.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GP3vRle5XrtO",
        "colab_type": "text"
      },
      "source": [
        "###Implementing Basic Block\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUzLSOKxYafp",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://raw.githubusercontent.com/torch/torch.github.io/master/blog/_posts/images/resnets_1.png)\n",
        "\n",
        "Resnet Image<br/>\n",
        "Here dotted skip connections imply change of dimension like from 64 to 128, from 128 to 256 and so on.\n",
        "![alt text](https://storage.googleapis.com/kaggle-datasets-images/6885/9959/d9e74a548a8cdca167b38520ac8bf405/data-original.png?t=2017-12-12-23-54-44)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-Iv7v6UXrPB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "    def __init__(self , input_channels , output_channels , stride = 1 , dim_change = None):\n",
        "        super(BasicBlock , self).__init__()\n",
        "        '''\n",
        "        First stride may differ. It can be 2 but then always 1\n",
        "        when you increase the stride you decrease the dimensions of the image.\n",
        "        For a 3*3 convolution to maintain the size stride must be 1 and padding 1\n",
        "        By default padding is 0. Since we want to decrease the dimensions in the \n",
        "        later layers we have a stride of 2 in the beginning layer. Same stride is \n",
        "        there in 1*1 convolution for down sampler since the residue dimensions should\n",
        "        be same as output to add them.\n",
        "        padding is always 0 for 1*1 convolutions.\n",
        "        '''\n",
        "        self.conv1 = nn.Conv2d(input_channels , output_channels , stride = stride , kernel_size = 3 , padding = 1)\n",
        "        self.bn1 = nn.BatchNorm2d(output_channels)\n",
        "        self.conv2 = nn.Conv2d(output_channels , output_channels , stride = 1 , kernel_size = 3 , padding = 1)\n",
        "        self.bn2 = nn.BatchNorm2d(output_channels)\n",
        "        self.dim_change = dim_change\n",
        "        \n",
        "    def forward(self , x):\n",
        "        residual_connection = x\n",
        "        output = F.relu(self.bn1(self.conv1(x)))\n",
        "        # No relu here since we have to add\n",
        "        output = self.bn2(self.conv2(output))\n",
        "        \n",
        "        #But first we will check for dimension change\n",
        "        if self.dim_change is not None:\n",
        "            residual_connection = self.dim_change(residual_connection)\n",
        "            \n",
        "        output = residual_connection + output\n",
        "        output = F.relu(output)\n",
        "        return output\n",
        "    \n",
        "# basic_block = BasicBlock(input_channels = 3, output_channels = 64, stride = 2)\n",
        "# print(basic_block)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fl0yMjK9Xx6P",
        "colab_type": "text"
      },
      "source": [
        "###Implementing Bottle neck block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MibmqVslH1s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BottleNeck(nn.Module):\n",
        "    # expansion will be used later when we define the full network\n",
        "    expansion = 4\n",
        "    def __init__(self , input_channels , output_channels , stride = 1 , dim_change = None):\n",
        "        super(BottleNeck , self).__init__()\n",
        "        self.conv1 = nn.Conv2d(input_channels , output_channels , stride = 1 , kernel_size = 1)\n",
        "        self.bn1 = nn.BatchNorm2d(output_channels)\n",
        "        self.conv2 = nn.Conv2d(output_channels , output_channels , stride = stride , padding = 1 , kernel_size = 3)\n",
        "        self.bn2 = nn.BatchNorm2d(output_channels)\n",
        "        self.conv3 = nn.Conv2d(output_channels , output_channels*4 , stride = 1 , kernel_size = 1)\n",
        "        self.bn3 = nn.BatchNorm2d(output_channels*4)\n",
        "        self.dim_change = dim_change\n",
        "        \n",
        "    def forward(self , x):\n",
        "        residual_connection = x\n",
        "        output = F.relu(self.bn1(self.conv1(x)))\n",
        "        output = F.relu(self.bn2(self.conv2(output)))\n",
        "        output = self.bn3(self.conv3(output))\n",
        "        \n",
        "        if self.dim_change is not None:\n",
        "            residual_connection = self.dim_change(residual_connection)\n",
        "            \n",
        "        output = output + residual_connection\n",
        "        output = F.relu(output)\n",
        "        return output\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxDon0sUnUpO",
        "colab_type": "text"
      },
      "source": [
        "###Assembling the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUFfnJNTnYMa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResNets(nn.Module):\n",
        "    def __init__(self , block , num_layers , classes = 10):\n",
        "        '''\n",
        "        The block can be bottleneck block or basic block and num_layers is the\n",
        "        number of layers required for each block. num_layers will be a list\n",
        "        '''\n",
        "        super(ResNets , self).__init__()\n",
        "        self.input_size = 64\n",
        "        # First layer in all is 7*7 convolution with stride 2\n",
        "        self.conv1 = nn.Conv2d(3, 64 , stride = 2 , kernel_size = 7)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        \n",
        "        # comment maxpool if you want to use it for cifar10 since image size is \n",
        "        # small 32*32 and maxpool would make it even smaller for processing\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        # These 4 segments form the starting part. Then we can start our layers\n",
        "        \n",
        "        # here _layer is a private function defined later in this block\n",
        "        # after the first one stride for all others are 2\n",
        "        self.layer1 = self._layer(block , 64 , num_layers[0] , stride = 1)\n",
        "        self.layer2 = self._layer(block , 128 , num_layers[1] , stride = 2)\n",
        "        self.layer3 = self._layer(block , 256 , num_layers[2] , stride = 2)\n",
        "        self.layer4 = self._layer(block , 512 , num_layers[3] , stride = 2)\n",
        "        \n",
        "        # then the end part\n",
        "        self.fc = nn.Linear(512*block.expansion , classes)\n",
        "        \n",
        "    def _layer(self , block , input_size ,num_layers , stride=1):\n",
        "        dim_change = None\n",
        "        # we have to find the condition for change of dimensions\n",
        "        # basically saying that change for dimensions 128,256,512\n",
        "        # input size gets updated later\n",
        "        if stride!=1 or input_size!=self.input_size*block.expansion:\n",
        "            dim_change = nn.Sequential(nn.Conv2d(self.input_size , input_size*block.expansion , kernel_size = 1 , stride = stride),\n",
        "                                       nn.BatchNorm2d(input_size*block.expansion))\n",
        "            \n",
        "        net_layers = []\n",
        "        # appending the layers\n",
        "        net_layers.append(block(self.input_size , input_size , stride , dim_change))\n",
        "        self.input_size = input_size*block.expansion\n",
        "        for i in range(1,num_layers):\n",
        "            net_layers.append(block(self.input_size , input_size))\n",
        "#             self.input_size = input_size*block.expansion\n",
        "            \n",
        "        return nn.Sequential(*net_layers)\n",
        "        \n",
        "    def forward(self , x):\n",
        "        # The beginning \n",
        "        x = F.relu(self.maxpool(self.bn1(self.conv1(x))))\n",
        "        # for cifar10 comment the above and uncomment the bottom one\n",
        "#         x = F.relu(self.bn1(self.conv1(x)))\n",
        "        \n",
        "        # The layers\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        \n",
        "        x = F.avg_pool2d(x,4)\n",
        "        # first element is always the batch size \n",
        "        x = x.reshape(x.size(0) , -1)\n",
        "        x = self.fc(x)\n",
        "        return x      \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ho2VWFE24LZs",
        "colab_type": "text"
      },
      "source": [
        "###Creating Resnets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fd3HqO7l4LzR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Creating_Resnets(number=18 , to_print=False):\n",
        "    \n",
        "    if number == 18:\n",
        "        resnet = ResNets(BasicBlock , [2,2,2,2] , 10)\n",
        "    elif number == 34:\n",
        "        resnet = ResNets(BasicBlock , [3,4,6,3] , 10)\n",
        "    elif number == 50:\n",
        "        resnet = ResNets(BottleNeck , [3,4,6,3] , 10)\n",
        "    elif number == 101:\n",
        "        resnet = ResNets(BottleNeck , [3,4,23,3] , 10)\n",
        "    elif number == 152:\n",
        "        resnet = ResNets(BottleNeck , [3,8,36,3] , 10)\n",
        "        \n",
        "    if to_print:\n",
        "        print(resnet)\n",
        "    return resnet\n",
        "\n",
        "resnet = Creating_Resnets(50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IaboaFrnbJ_",
        "colab_type": "text"
      },
      "source": [
        "##Viewing and Testing the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANgZouKIfHQn",
        "colab_type": "code",
        "outputId": "6a1e1a1c-fc3c-422c-b082-2c89720c6bc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "def test():\n",
        "    y = resnet(torch.randn(1,3,32,32))\n",
        "    print(y.size())\n",
        "\n",
        "test()"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkNcLSAzGVy4",
        "colab_type": "code",
        "outputId": "3b6bd7c5-3fc3-44da-f7bf-498fddc722a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "!pip install onnx\n",
        "dummy_input = torch.randn(1, 3, 224, 224)\n",
        "torch.onnx.export(resnet, dummy_input, \"resnet.onnx\")\n",
        "print(\"Model Expoeted for viewing\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: onnx in /usr/local/lib/python3.6/dist-packages (1.5.0)\n",
            "Requirement already satisfied: typing>=3.6.4 in /usr/local/lib/python3.6/dist-packages (from onnx) (3.6.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from onnx) (1.16.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from onnx) (1.12.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from onnx) (3.7.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.6/dist-packages (from onnx) (3.7.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->onnx) (41.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}